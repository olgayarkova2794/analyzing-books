{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe70ff6-c378-461b-abfa-49fce2344fd3",
   "metadata": {},
   "source": [
    "# PDF to WORD"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a71eecd0-34fa-4807-9925-b642408cda75",
   "metadata": {},
   "source": [
    "–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ñ–∞–π–ª—ã PDF –≤ Word. –£ –Ω–∞—Å –ø–æ—á—Ç–∏ –Ω–µ—Ç pdf —Ñ–∞–π–ª–æ–≤, –ø–æ—ç—Ç–æ–º—É —ç—Ç–æ—Ç –∫–æ–¥ –Ω–µ –∞–ø–¥–µ–π—Ç–∏–ª—Å—è –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≥–ª–∞–≤ –Ω–µ –±—É–¥—É—Ç –≤—ã–¥–µ–ª–µ–Ω—ã –≤ —Ç–∞–∫–æ–º —Ñ–∞–π–ª–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d787a-1518-4c4b-8bb4-77e1be7e9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2docx import Converter\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "import os\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# –í–∏–¥–∂–µ—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏\n",
    "\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept='.pdf',  # –ü—Ä–∏–Ω–∏–º–∞–µ–º —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã .pdf\n",
    "    multiple=False  # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ñ–∞–π–ª\n",
    ")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫—É\n",
    "convert_button = widgets.Button(\n",
    "    description='Convert',\n",
    "    disabled=False,\n",
    "    button_style='',  # 'success', 'info', 'warning', 'danger' –∏–ª–∏ ''\n",
    "    tooltip='Convert',\n",
    "    icon=''  # –ò–∫–æ–Ω–∫–∞ (–∏–º—è FontAwesome –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ `fa-`)\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_convert_button_click(event):\n",
    "    with output:\n",
    "        output.clear_output()  # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –≤—ã–≤–æ–¥\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–µ –ø—É—Å—Ç–æ–µ\n",
    "        if upload_widget.value:\n",
    "            print(\"upload_widget.value —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ:\", upload_widget.value)  # –û—Ç–æ–±—Ä–∞–∑–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏\n",
    "            \n",
    "            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –∫–æ—Ä—Ç–µ–∂–∞\n",
    "            file_info = upload_widget.value[0]\n",
    "            print(\"file_info:\", file_info)  # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É file_info\n",
    "            \n",
    "            # –ü—Ä–æ–≤–µ—Ä–∏–º, –µ—Å—Ç—å –ª–∏ –∫–ª—é—á–∏ 'name' –∏ 'content'\n",
    "            if 'name' in file_info and 'content' in file_info:\n",
    "                filename = file_info['name']  # –ò–º—è —Ñ–∞–π–ª–∞\n",
    "                print(f'–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {filename}')\n",
    "                \n",
    "                # –°–æ—Ö—Ä–∞–Ω—è–µ–º PDF –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª\n",
    "                pdf_path = filename if filename.endswith('.pdf') else filename + '.pdf'\n",
    "                with open(pdf_path, 'wb') as f:\n",
    "                    f.write(file_info['content'])\n",
    "                \n",
    "                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è DOCX\n",
    "                docx_path = pdf_path.replace('.pdf', '.docx')\n",
    "                \n",
    "                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ DOCX\n",
    "                convert_pdf_to_docx(pdf_path, docx_path)\n",
    "                \n",
    "                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π PDF —Ñ–∞–π–ª, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–µ–Ω\n",
    "                os.remove(pdf_path)\n",
    "            else:\n",
    "                print(\"–û—à–∏–±–∫–∞: –∫–ª—é—á–∏ 'name' –∏ 'content' –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ file_info.\")\n",
    "        else:\n",
    "            print(\"–§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω –∏–ª–∏ upload_widget.value –ø—É—Å—Ç.\")\n",
    "\n",
    "\n",
    "\n",
    "convert_button.on_click(on_convert_button_click)\n",
    "\n",
    "display(upload_widget, convert_button, output)\n",
    "\n",
    "def convert_pdf_to_docx(pdf_path, docx_path):\n",
    "    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞\n",
    "    cv = Converter(pdf_path)\n",
    "    \n",
    "    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ DOCX\n",
    "    cv.convert(docx_path, start=0, end=None)\n",
    "    \n",
    "    # –ó–∞–∫—Ä—ã–≤–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä\n",
    "    cv.close()\n",
    "    print(f\"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ {docx_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e831a-4538-4e34-8e75-abd9f823293c",
   "metadata": {},
   "source": [
    "# TXT to WORD"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0374b91-d154-41a3-a30c-fde4619f01f9",
   "metadata": {},
   "source": [
    "–≠—Ç–æ—Ç –∫–æ–¥ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ñ–∞–π–ª txt, –≤ –∫–æ—Ç–æ—Ä–æ–º —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –±–æ–ª—å—à–∞—è —á–∞—Å—Ç—å –Ω–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤, –≤ —Ñ–∞–π–ª Docx —Å –≥–ª–∞–≤–∞–º–∏, –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∏. –ú–æ–∂–Ω–æ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É —Å –ø–æ–º–æ—â—å—é –í–∏–¥ - –ù–∞–≤–∏–≥–∞—Ü–∏—è –≤ Word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f9c828-b159-40e7-82e8-f56923eca5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FileUpload, Text, Button, Output, VBox\n",
    "from IPython.display import display\n",
    "from docx import Document\n",
    "import re\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –≤–∏–¥–∂–µ—Ç—ã\n",
    "upload_widget = FileUpload(accept='.txt', multiple=False)  # –í–∏–¥–∂–µ—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞\n",
    "output_name_widget = Text(placeholder='–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —Ñ–∞–π–ª–∞ .docx', description='–ò–º—è —Ñ–∞–π–ª–∞:')\n",
    "process_button = Button(description='–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å')  # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
    "output_widget = Output()  # –í–∏–¥–∂–µ—Ç –¥–ª—è –≤—ã–≤–æ–¥–∞ —Å–æ–æ–±—â–µ–Ω–∏–π\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ .docx\n",
    "def process_file(_):\n",
    "    with output_widget:\n",
    "        output_widget.clear_output()\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≥—Ä—É–∂–µ–Ω –ª–∏ —Ñ–∞–π–ª\n",
    "        if not upload_widget.value:\n",
    "            print(\"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª .txt.\")\n",
    "            return\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É–∫–∞–∑–∞–Ω–æ –ª–∏ –∏–º—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞\n",
    "        if not output_name_widget.value.strip():\n",
    "            print(\"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –∏–º—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ .docx.\")\n",
    "            return\n",
    "        \n",
    "        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞\n",
    "        uploaded_files = upload_widget.value  # –≠—Ç–æ –∫–æ—Ä—Ç–µ–∂ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n",
    "        if not uploaded_files:\n",
    "            print(\"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª.\")\n",
    "            return\n",
    "        \n",
    "        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª\n",
    "        uploaded_file = list(uploaded_files.values())[0] if isinstance(uploaded_files, dict) else uploaded_files[0]\n",
    "        content = bytes(uploaded_file['content']).decode('utf-8')  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º memoryview –≤ bytes –∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ–º\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç\n",
    "        doc = Document()\n",
    "        \n",
    "        # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ \"Chapter + –Ω–æ–º–µ—Ä\"\n",
    "        chapter_pattern = re.compile(r'^Chapter\\s+\\d+', re.IGNORECASE)\n",
    "        \n",
    "        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏—Ö\n",
    "        lines = content.splitlines()\n",
    "        for line in lines:\n",
    "            stripped_line = line.strip()\n",
    "            if chapter_pattern.match(stripped_line):\n",
    "                doc.add_heading(stripped_line, level=1)\n",
    "            else:\n",
    "                doc.add_paragraph(stripped_line)\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –∏–º–µ–Ω–µ–º\n",
    "        output_file = f\"{output_name_widget.value.strip()}.docx\"\n",
    "        doc.save(output_file)\n",
    "        \n",
    "        # –í—ã–≤–æ–¥–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± —É—Å–ø–µ—à–Ω–æ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏\n",
    "        print(f\"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ '{output_file}'\")\n",
    "\n",
    "# –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∫ –∫–Ω–æ–ø–∫–µ\n",
    "process_button.on_click(process_file)\n",
    "\n",
    "# –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤–∏–¥–∂–µ—Ç—ã\n",
    "display(VBox([upload_widget, output_name_widget, process_button, output_widget]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572673a6-81fc-4a0a-8ef0-51cbbeeb2025",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–º–ø—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–∞–º–º–∞—Ä–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã–π"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b96ddc7f-2c55-4be3-b8f4-63f9783b7afe",
   "metadata": {},
   "source": [
    "–≠—Ç–æ –Ω—É–∂–Ω–æ –ø–∏—Å–∞—Ç—å —Ç–æ–ª—å–∫–æ –≤ –ø–µ—Ä–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ –≤ —á–∞—Ç–µ. –î–∞–ª–µ–µ –ø—Ä–æ—Å—Ç–æ –≥—Ä—É–∑–∏–º –¥–æ–∫–∏ —Å –≥–ª–∞–≤–∞–º–∏ –ø–æ –æ–¥–Ω–æ–π –≤ –æ–∫–æ—à–∫–æ. –§–ê–ô–õ–ê–ú–ò, –Ω–µ —Ç–µ–∫—Å—Ç–æ–º.\n",
    "–ü—Ä–æ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É - –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ.\n",
    "–ï—Å–ª–∏ —á–∞—Ç –∑–∞–≤–∏—Å –∏ –Ω—É–∂–Ω–æ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å 1-2 –≥–ª–∞–≤—ã –∏–∑ —Ç–µ—Ö, —á—Ç–æ —É–∂–µ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã, —á—Ç–æ–±—ã –ª—É—á—à–µ –±—ã–ª –ø–æ–Ω—è—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc7dfe85-6712-422a-b89c-44a24b51615e",
   "metadata": {},
   "source": [
    "Use temperature=0.3. –°–¥–µ–ª–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–π –≥–ª–∞–≤—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º:\n",
    "    –ì–ª–∞–≤–∞+–Ω–æ–º–µ—Ä\n",
    "    –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≥–ª–∞–≤—ã: (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "    –°–æ–±—ã—Ç–∏—è –≥–ª–∞–≤—ã: 2-3 –∞–±–∑–∞—Ü–∞\n",
    "    –ü–µ—Ä—Å–æ–Ω–∞–∂–∏ –≥–ª–∞–≤—ã: –∏–º–µ–Ω–∞ + –≤–Ω–µ—à–Ω–æ—Å—Ç—å (–≤–æ–∑—Ä–∞—Å—Ç/–∫–æ–∂–∞/–≤–æ–ª–æ—Å—ã/–≥–ª–∞–∑–∞/—Ä–æ—Å—Ç/–æ–¥–µ–∂–¥–∞, –∫–æ—Ç–æ—Ä—É—é –Ω–∞–¥–µ–ª–∏ –∏–ª–∏ —Å–Ω—è–ª–∏/–ø–æ–∑–∞)\n",
    "    –õ–æ–∫–∞—Ü–∏–∏ –≥–ª–∞–≤—ã: –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –æ–ø–∏—Å–∞–Ω–∏—è —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –≤–∏–∑—É–∞–ª\n",
    "    –ü–æ–≥–æ–¥–∞ –∏ –≤—Ä–µ–º—è –¥–Ω—è: (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ)\n",
    "    \n",
    "    –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–∏ –∂–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å –¥–≤–æ–µ—Ç–æ—á–∏—è–º–∏, –æ—Ç–¥–µ–ª—è–π —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–æ–π. –ò–∑–±–µ–≥–∞–π –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–π –∏ –ø–æ–≤—Ç–æ—Ä–æ–≤ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ.\n",
    "     –¢–µ–∫—Å—Ç –≥–ª–∞–≤—ã:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc4c7ea-babe-4dd2-9ce8-2c7a9e5ed020",
   "metadata": {},
   "source": [
    "# –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5296c-47cc-4731-8886-82252db8443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "–ü–æ—Å–ª–µ Split Chapters –∏–¥–µ–º –≤ ChatGPT –∏ –ø–æ–ª—É—á–∞–µ–º —Å–∞–º–º–∞—Ä–∏ —Å –ø–æ–º–æ—â—å—é –ø—Ä–æ–º–ø—Ç–∞ –≤—ã—à–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "569b6e4d-c218-4b26-8fa1-32d17f460ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9434ca2b7664de29187ff46bbc7404d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.docx', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7a587704674f1abfcf866ca1b1e160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Check', style=ButtonStyle(), tooltip='Check')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d755bf72894287ad562b02212a2873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Split', style=ButtonStyle(), tooltip='Split')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e2b44505cc4e5cbdcabb405c81b9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Find Appearance', style=ButtonStyle(), tooltip='Find Appearance')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92b0c75afc34c35b72b7acb829ad43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Clean summary', style=ButtonStyle(), tooltip='Clean summary')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d310732931764114acbd49be35ab8e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Create cover file', style=ButtonStyle(), tooltip='Create cover file')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8900677fe75e4f60a0b64e3d7368cef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Fix Chapters (opt)', style=ButtonStyle(), tooltip='Fix Chapters (opt)')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea96506f74a944d49cf68ddbcd3a28f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Custom split', style=ButtonStyle(), tooltip='Custom summary split')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0c944afadb4d2cb7209eb3a13a1c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "import pythoncom\n",
    "import math\n",
    "from win32com import client as win32\n",
    "\n",
    "from IPython.display import display\n",
    "from docx import Document\n",
    "from collections import defaultdict\n",
    "from words import (\n",
    "    clothes_words, hair_words, appearances_words, weather_words,\n",
    "    locations_words, age_words, other_words\n",
    ")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –≤–∏–¥–∂–µ—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept = '.docx',  # –ü—Ä–∏–Ω–∏–º–∞–µ–º —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã .docx\n",
    "    multiple = False  # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ñ–∞–π–ª\n",
    ")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫–∏\n",
    "analyze_button = widgets.Button(\n",
    "    description = 'Check',\n",
    "    disabled = False,\n",
    "    button_style = '',  # 'success', 'info', 'warning', 'danger' –∏–ª–∏ ''\n",
    "    tooltip = 'Check',\n",
    "    icon = ''  # –ò–∫–æ–Ω–∫–∞ (–∏–º—è FontAwesome –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ `fa-`)\n",
    ")\n",
    "\n",
    "split_by_chapters_button = widgets.Button(\n",
    "    description = 'Split',\n",
    "    disabled = False,\n",
    "    button_style = '',  # 'success', 'info', 'warning', 'danger' –∏–ª–∏ ''\n",
    "    tooltip = 'Split',\n",
    "    icon = ''  # –ò–∫–æ–Ω–∫–∞ (–∏–º—è FontAwesome –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ `fa-`)\n",
    ")\n",
    "\n",
    "find_appearance_button = widgets.Button(\n",
    "    description = 'Find Appearance',\n",
    "    disabled = False,\n",
    "    button_style = '',  # 'success', 'info', 'warning', 'danger' –∏–ª–∏ ''\n",
    "    tooltip = 'Find Appearance',\n",
    "    icon = ''  # –ò–∫–æ–Ω–∫–∞ (–∏–º—è FontAwesome –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ `fa-`)\n",
    ")\n",
    "\n",
    "clean_summary_button = widgets.Button(\n",
    "    description = 'Clean summary',\n",
    "    disabled = False,\n",
    "    button_style = '',  # 'success', 'info', 'warning', 'danger' –∏–ª–∏ ''\n",
    "    tooltip = 'Clean summary',\n",
    "    icon = ''  # –ò–∫–æ–Ω–∫–∞ (–∏–º—è FontAwesome –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ `fa-`)\n",
    ")\n",
    "\n",
    "cover_info_button = widgets.Button(\n",
    "    description = 'Create cover file',\n",
    "    disabled = False,\n",
    "    button_style = '',  # 'success', 'info', 'warning', 'danger' –∏–ª–∏ ''\n",
    "    tooltip = 'Create cover file',\n",
    "    icon = ''  # –ò–∫–æ–Ω–∫–∞ (–∏–º—è FontAwesome –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ `fa-`)\n",
    ")\n",
    "\n",
    "fix_chapters_button = widgets.Button(\n",
    "    description = 'Fix Chapters (opt)',\n",
    "    disabled = False,\n",
    "    button_style = '',  # 'success', 'info', 'warning', 'danger' –∏–ª–∏ ''\n",
    "    tooltip = 'Fix Chapters (opt)',\n",
    "    icon = ''  # –ò–∫–æ–Ω–∫–∞ (–∏–º—è FontAwesome –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ `fa-`)\n",
    ")\n",
    "\n",
    "custom_split_button = widgets.Button(\n",
    "    description = 'Custom split',\n",
    "    disabled = False,\n",
    "    button_style = '',  # 'success', 'info', 'warning', 'danger' –∏–ª–∏ ''\n",
    "    tooltip = 'Custom summary split',\n",
    "    icon = ''  # –ò–∫–æ–Ω–∫–∞ (–∏–º—è FontAwesome –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ `fa-`)\n",
    ")\n",
    "\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –≤–∏–¥–∂–µ—Ç –≤—ã–≤–æ–¥–∞\n",
    "output = widgets.Output()\n",
    "\n",
    "def convert_docm_to_docx(input_path, output_path):\n",
    "    \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ñ–∞–π–ª .docm –≤ .docx —Å –ø–æ–º–æ—â—å—é Microsoft Word.\"\"\"\n",
    "    try:\n",
    "        pythoncom.CoInitialize()\n",
    "        word = win32.Dispatch(\"Word.Application\")\n",
    "        word.Visible = False  # –ó–∞–ø—É—Å–∫ Word –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ\n",
    "\n",
    "        print(f\"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è {input_path} –≤ {output_path}...\")\n",
    "        doc = word.Documents.Open(input_path)\n",
    "        doc.SaveAs(output_path, FileFormat=16)  # 16 ‚Äî —ç—Ç–æ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è .docx\n",
    "        doc.Close()\n",
    "        word.Quit()\n",
    "        print(f\"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω: {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        pythoncom.CoUninitialize()\n",
    "\n",
    "\n",
    "def is_valid_docx(file_content):\n",
    "    \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–Ω–æ –ª–∏ –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç Word.\"\"\"\n",
    "    try:\n",
    "        docx_file = io.BytesIO(file_content)\n",
    "        Document(docx_file)  # –ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–∫ .docx\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def load_docx_file(file_info):\n",
    "    try:\n",
    "        filename = file_info['name']\n",
    "        file_content = file_info['content']\n",
    "\n",
    "        if not is_valid_docx(file_content):\n",
    "            print(f\"–û—à–∏–±–∫–∞: –§–∞–π–ª {filename} –ø–æ–≤—Ä–µ–∂–¥—ë–Ω –∏–ª–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º .docx/.docm.\")\n",
    "            return None  # –î–æ–±–∞–≤–ª—è–µ–º return –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –∑–∞–≤–µ—Ä—à–∏—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ\n",
    "\n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª .docm\n",
    "        if filename.endswith('.docm'):\n",
    "            print(\"–û–±–Ω–∞—Ä—É–∂–µ–Ω .docm —Ñ–∞–π–ª, –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è...\")\n",
    "            temp_docm_path = \"temp_file.docm\"\n",
    "            with open(temp_docm_path, 'wb') as f:\n",
    "                f.write(file_content)\n",
    "\n",
    "            temp_docx_path = \"temp_file.docx\"\n",
    "            if convert_docm_to_docx(temp_docm_path, temp_docx_path):\n",
    "                print(\"–ó–∞–≥—Ä—É–∑–∫–∞ —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ .docx —Ñ–∞–π–ª–∞...\")\n",
    "                with open(temp_docx_path, 'rb') as f:\n",
    "                    docx_file = io.BytesIO(f.read())\n",
    "\n",
    "                # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n",
    "                os.remove(temp_docm_path)\n",
    "                os.remove(temp_docx_path)\n",
    "            else:\n",
    "                print(\"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å.\")\n",
    "                return None\n",
    "        else:\n",
    "            print(\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —Ñ–∞–π–ª .docx...\")\n",
    "            docx_file = io.BytesIO(file_content)\n",
    "\n",
    "        # –ü—ã—Ç–∞–µ–º—Å—è –æ—Ç–∫—Ä—ã—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç Word\n",
    "        docx = Document(docx_file)\n",
    "        print(\"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –ø—Ä–æ—á–∏—Ç–∞–Ω.\")\n",
    "        return docx\n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}\")\n",
    "        return None\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–æ–∫\n",
    "def on_analyze_button_click(event):\n",
    "    with output:\n",
    "        output.clear_output()  # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –≤—ã–≤–æ–¥\n",
    "        if upload_widget.value:\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ—Ä—Ç–µ–∂–∞ (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ)\n",
    "            file_info = list(upload_widget.value)[0]\n",
    "            filename = file_info['name']  # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞\n",
    "            print(f'–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {filename}')\n",
    "            \n",
    "            docx_doc = load_docx_file(file_info)\n",
    "            analyze_book(docx_doc)\n",
    "        else:\n",
    "            print(\"–§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω\")\n",
    "\n",
    "def on_split_by_chapters_button_click(event):\n",
    "    with output:\n",
    "        output.clear_output()  # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –≤—ã–≤–æ–¥\n",
    "        if upload_widget.value:\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ—Ä—Ç–µ–∂–∞ (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ)\n",
    "            file_info = list(upload_widget.value)[0]\n",
    "            filename = file_info['name']  # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞\n",
    "            \n",
    "            print(f'–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {filename}')\n",
    "\n",
    "            path = os.path.splitext(filename)[0]\n",
    "            docx_doc = load_docx_file(file_info)\n",
    "            \n",
    "            split_chapters(docx_doc, path)\n",
    "        else:\n",
    "            print(\"–§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω\")\n",
    "\n",
    "def on_find_appearance_button_click(event):\n",
    "    with output:\n",
    "        output.clear_output()  # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –≤—ã–≤–æ–¥\n",
    "        if upload_widget.value:\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ—Ä—Ç–µ–∂–∞ (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ)\n",
    "            file_info = list(upload_widget.value)[0]\n",
    "            filename = file_info['name']  # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞\n",
    "            \n",
    "            print(f'–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {filename}')\n",
    "\n",
    "            path = os.path.splitext(filename)[0]\n",
    "            docx_doc = load_docx_file(file_info)\n",
    "            \n",
    "            find_appearance(docx_doc, path)\n",
    "        else:\n",
    "            print(\"–§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω\")\n",
    "\n",
    "def on_clean_summary_button_click(event):\n",
    "    with output:\n",
    "        output.clear_output()  # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –≤—ã–≤–æ–¥\n",
    "        if upload_widget.value:\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ—Ä—Ç–µ–∂–∞ (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ)\n",
    "            file_info = list(upload_widget.value)[0]\n",
    "            filename = file_info['name']  # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞\n",
    "            \n",
    "            print(f'–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {filename}')\n",
    "\n",
    "            path = os.path.splitext(filename)[0]\n",
    "            docx_doc = load_docx_file(file_info)\n",
    "            \n",
    "            clean_summary(docx_doc, path)\n",
    "        else:\n",
    "            print(\"–§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω\")\n",
    "\n",
    "def on_cover_info_button_click(event):\n",
    "    with output:\n",
    "        output.clear_output()  # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –≤—ã–≤–æ–¥\n",
    "        if upload_widget.value:\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ—Ä—Ç–µ–∂–∞ (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ)\n",
    "            file_info = list(upload_widget.value)[0]\n",
    "            filename = file_info['name']  # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞\n",
    "            \n",
    "            print(f'–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {filename}')\n",
    "\n",
    "            path = os.path.splitext(filename)[0]\n",
    "            docx_doc = load_docx_file(file_info)\n",
    "            \n",
    "            create_cover_info(docx_doc, path)\n",
    "        else:\n",
    "            print(\"–§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω\")\n",
    "\n",
    "def on_fix_chapters_button_click(event):\n",
    "    with output:\n",
    "        output.clear_output()  # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –≤—ã–≤–æ–¥\n",
    "        if upload_widget.value:\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ—Ä—Ç–µ–∂–∞ (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ)\n",
    "            file_info = list(upload_widget.value)[0]\n",
    "            filename = file_info['name']  # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞\n",
    "            \n",
    "            print(f'–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {filename}')\n",
    "\n",
    "            path = os.path.splitext(filename)[0]\n",
    "            doc = load_docx_file(file_info)\n",
    "        \n",
    "            fix_chapters(doc, path)\n",
    "        else:\n",
    "            print(\"–§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω\")\n",
    "\n",
    "def on_custom_split_button_click(event):\n",
    "    with output:\n",
    "        output.clear_output()  # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –≤—ã–≤–æ–¥\n",
    "        if upload_widget.value:\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ—Ä—Ç–µ–∂–∞ (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ)\n",
    "            file_info = list(upload_widget.value)[0]\n",
    "            filename = file_info['name']  # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞\n",
    "            \n",
    "            print(f'–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {filename}')\n",
    "\n",
    "            path = os.path.splitext(filename)[0]\n",
    "            doc = load_docx_file(file_info)\n",
    "        \n",
    "            custom_split(path)\n",
    "        else:\n",
    "            print(\"–§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω\")\n",
    "\n",
    "# –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∫ –∫–Ω–æ–ø–∫–µ\n",
    "analyze_button.on_click(on_analyze_button_click)\n",
    "split_by_chapters_button.on_click(on_split_by_chapters_button_click)\n",
    "find_appearance_button.on_click(on_find_appearance_button_click)\n",
    "clean_summary_button.on_click(on_clean_summary_button_click)\n",
    "cover_info_button.on_click(on_cover_info_button_click)\n",
    "fix_chapters_button.on_click(on_fix_chapters_button_click)\n",
    "custom_split_button.on_click(on_custom_split_button_click)\n",
    "\n",
    "# –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤–∏–¥–∂–µ—Ç—ã\n",
    "display(upload_widget, analyze_button, split_by_chapters_button, find_appearance_button, clean_summary_button, cover_info_button, fix_chapters_button, custom_split_button, output)\n",
    "\n",
    "# –°–ª–æ–≤–∞—Ä—å –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —á–∏—Å–µ–ª –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞\n",
    "TEXT_NUMBERS = {\n",
    "    'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6,\n",
    "    'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10, 'eleven': 11, 'twelve': 12,\n",
    "    'thirteen': 13, 'fourteen': 14, 'fifteen': 15, 'sixteen': 16,\n",
    "    'seventeen': 17, 'eighteen': 18, 'nineteen': 19, 'twenty': 20,\n",
    "    'thirty': 30, 'forty': 40, 'fifty': 50, 'sixty': 60, 'seventy': 70,\n",
    "    'eighty': 80, 'ninety': 90, 'hundred': 100\n",
    "}\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "### 00_book_Check ###\n",
    "\n",
    "def word_to_number(word):\n",
    "    \"\"\"–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —á–∏—Å–ª–æ –≤ —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.\"\"\"\n",
    "    words = re.split(r'[\\s\\-]+', word.lower())  # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø—Ä–æ–±–µ–ª–∞–º –∏ –¥–µ—Ñ–∏—Å–∞–º\n",
    "    number = 0\n",
    "    temp = 0\n",
    "\n",
    "    for w in words:\n",
    "        if w in TEXT_NUMBERS:\n",
    "            scale = TEXT_NUMBERS[w]\n",
    "            if scale == 100:  # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ—Ç–µ–Ω, –Ω–∞–ø—Ä–∏–º–µ—Ä \"one hundred\"\n",
    "                temp *= scale\n",
    "            else:\n",
    "                temp += scale\n",
    "        else:\n",
    "            return None  # –ï—Å–ª–∏ —Å–ª–æ–≤–æ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None\n",
    "\n",
    "    number += temp\n",
    "    return number\n",
    "\n",
    "def extract_chapter_number(text):\n",
    "    \"\"\"–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä –≥–ª–∞–≤—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞.\"\"\"\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç, –Ω–∞–ø—Ä–∏–º–µ—Ä, \"Chapter 1\" –∏–ª–∏ \"Chapter 1 - School Trouble\"\n",
    "    numeric_match = re.match(r'Chapter\\s+(\\d+)', text, re.IGNORECASE)\n",
    "    if numeric_match:\n",
    "        return int(numeric_match.group(1))\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç, –Ω–∞–ø—Ä–∏–º–µ—Ä, \"Chapter One\" –∏–ª–∏ \"Chapter Thirty-one\"\n",
    "    text_match = re.match(r'Chapter\\s+([\\w\\s\\-]+)', text, re.IGNORECASE)\n",
    "    if text_match:\n",
    "        word = text_match.group(1).strip()\n",
    "        return word_to_number(word)\n",
    "    return None\n",
    "\n",
    "def extract_chapters(doc):\n",
    "    \"\"\"–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≥–ª–∞–≤—ã –∏ –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑ .docx —Ñ–∞–π–ª–∞.\"\"\"\n",
    "    chapters = []\n",
    "    current_chapter = None\n",
    "    current_text = []\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        chapter_num = extract_chapter_number(para.text.strip())\n",
    "        if chapter_num is not None:\n",
    "            if current_chapter is not None and current_text:\n",
    "                chapters.append((current_chapter, \"\\n\".join(current_text).strip()))\n",
    "            current_chapter = chapter_num\n",
    "            current_text = []\n",
    "        else:\n",
    "            current_text.append(para.text.strip())\n",
    "\n",
    "    if current_chapter is not None and current_text:\n",
    "        chapters.append((current_chapter, \"\\n\".join(current_text).strip()))\n",
    "\n",
    "    return chapters\n",
    "\n",
    "def check_duplicate_chapters(chapters):\n",
    "    chapter_numbers = [chap[0] for chap in chapters]\n",
    "    return {chap for chap in chapter_numbers if chapter_numbers.count(chap) > 1}\n",
    "\n",
    "def check_text_duplicates(chapters):\n",
    "    \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–π—Å—è —Ç–µ–∫—Å—Ç –≤ –≥–ª–∞–≤–∞—Ö —Å —É—á—ë—Ç–æ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏.\"\"\"\n",
    "    text_to_chapter = defaultdict(list)\n",
    "\n",
    "    for chapter, text in chapters:\n",
    "        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç: —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n",
    "        normalized_text = \" \".join(text.split()).lower()\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–º–µ—Ä –≥–ª–∞–≤—ã –≤ —Å–ø–∏—Å–æ–∫ –≥–ª–∞–≤ —Å —Ç–∞–∫–∏–º –∂–µ —Ç–µ–∫—Å—Ç–æ–º\n",
    "        text_to_chapter[normalized_text].append(chapter)\n",
    "\n",
    "    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –∑–∞–ø–∏—Å–∏, –≥–¥–µ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —Ç–µ–∫—Å—Ç –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –±–æ–ª–µ–µ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–∞\n",
    "    return {text: chaps for text, chaps in text_to_chapter.items() if len(chaps) > 1}\n",
    "\n",
    "def check_chapter_order(chapters):\n",
    "    chapter_numbers = [chap[0] for chap in chapters]\n",
    "    return [(chapter_numbers[i], chapter_numbers[i+1]) \n",
    "            for i in range(len(chapter_numbers) - 1) if chapter_numbers[i] > chapter_numbers[i + 1]]\n",
    "\n",
    "def check_missing_chapters(chapters):\n",
    "    \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –≥–ª–∞–≤—ã –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\"\"\"\n",
    "    chapter_numbers = sorted([chap[0] for chap in chapters])\n",
    "    missing_chapters = [num for num in range(chapter_numbers[0], chapter_numbers[-1] + 1) \n",
    "                        if num not in chapter_numbers]\n",
    "    return missing_chapters\n",
    "\n",
    "def analyze_book(docx_file):\n",
    "    chapters = extract_chapters(docx_file)\n",
    "\n",
    "    print(\"–°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≥–ª–∞–≤:\")\n",
    "    for chapter, text in chapters:\n",
    "        print(f\"Chapter {chapter}: {text[:50]}...\")\n",
    "    \n",
    "    duplicate_chapters = check_duplicate_chapters(chapters)\n",
    "    duplicate_texts = check_text_duplicates(chapters)\n",
    "    unordered_chapters = check_chapter_order(chapters)\n",
    "    missing_chapters = check_missing_chapters(chapters)\n",
    "\n",
    "    print(\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–æ–∫:\")\n",
    "    print(f\"‚ùå –ù–∞–π–¥–µ–Ω—ã –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –≥–ª–∞–≤—ã: {duplicate_chapters}\" if duplicate_chapters else \"‚úÖ –ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –≥–ª–∞–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\")\n",
    "    print(f\"‚ùå –ù–∞–π–¥–µ–Ω—ã –≥–ª–∞–≤—ã —Å –¥—É–±–ª–∏—Ä—É—é—â–∏–º—Å—è —Ç–µ–∫—Å—Ç–æ–º: {duplicate_texts}\" if duplicate_texts else \"‚úÖ –î—É–±–ª–∏—Ä—É—é—â–∏–π—Å—è —Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.\")\n",
    "    print(f\"‚ùå –ù–∞–π–¥–µ–Ω—ã –≥–ª–∞–≤—ã —Å –Ω–∞—Ä—É—à–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞: {unordered_chapters}\" if unordered_chapters else \"‚úÖ –ù–∞—Ä—É—à–µ–Ω–∏–π –≤ –ø–æ—Ä—è–¥–∫–µ –≥–ª–∞–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.\")\n",
    "    print(f\"‚ùå –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –≥–ª–∞–≤—ã: {missing_chapters}\" if missing_chapters else \"‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –≥–ª–∞–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.\")\n",
    "\n",
    "### 01_Breaking_into_chapters ###\n",
    "\n",
    "def split_chapters(doc, path):\n",
    "    #print('split_chapters(doc_path in doc.paragraph)')\n",
    "    # –ë—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ç–µ–∫—É—â–µ–π –≥–ª–∞–≤—ã\n",
    "    current_chapter = []\n",
    "    chapter_number = 0\n",
    "\n",
    "    # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≥–ª–∞–≤, –≤–∫–ª—é—á–∞—è –¥–µ—Ñ–∏—Å\n",
    "    chapter_pattern = re.compile('Chapter', re.IGNORECASE)\n",
    "    found_first_chapter = False  # –§–ª–∞–≥ –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–æ –ø–µ—Ä–≤–æ–π –≥–ª–∞–≤—ã\n",
    "\n",
    "    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º –¥–æ–∫—É–º–µ–Ω—Ç–∞\n",
    "    for paragraph in doc.paragraphs:\n",
    "        # –ï—Å–ª–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫—É –≥–ª–∞–≤—ã\n",
    "        if chapter_pattern.match(paragraph.text.strip()):\n",
    "            if found_first_chapter and current_chapter:\n",
    "                save_chapter(current_chapter, chapter_number, path)\n",
    "\n",
    "            # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä –¥–ª—è –Ω–æ–≤–æ–π –≥–ª–∞–≤—ã –∏ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –Ω–æ–º–µ—Ä –≥–ª–∞–≤—ã\n",
    "            current_chapter = [paragraph.text]\n",
    "            chapter_number += 1\n",
    "            found_first_chapter = True  # –ü–µ—Ä–≤–∞—è –≥–ª–∞–≤–∞ –Ω–∞–π–¥–µ–Ω–∞\n",
    "        else:\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –≤ —Ç–µ–∫—É—â—É—é –≥–ª–∞–≤—É, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–µ—Ä–≤–∞—è –≥–ª–∞–≤–∞ —É–∂–µ –Ω–∞–π–¥–µ–Ω–∞\n",
    "            if found_first_chapter:\n",
    "                current_chapter.append(paragraph.text)\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≥–ª–∞–≤—É\n",
    "    if current_chapter:\n",
    "        save_chapter(current_chapter, chapter_number, path)\n",
    "\n",
    "def save_chapter(chapter_content, chapter_number, path):\n",
    "    print('save')\n",
    "    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –≥–ª–∞–≤—ã\n",
    "    new_doc = Document()\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≥–ª–∞–≤—ã –≤ –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç\n",
    "    for paragraph in chapter_content:\n",
    "        new_doc.add_paragraph(paragraph)\n",
    "    \n",
    "    # –£–∫–∞–∑—ã–≤–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n",
    "    save_directory = f'{path}/chapters'  # –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –Ω—É–∂–Ω—ã–π –ø—É—Ç—å\n",
    "    \n",
    "    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –ø–∞–ø–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî —Å–æ–∑–¥–∞–µ–º\n",
    "    os.makedirs(save_directory, exist_ok = True)\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º Chapter_N.docx –≤ —É–∫–∞–∑–∞–Ω–Ω—É—é –ø–∞–ø–∫—É\n",
    "    chapter_filename = os.path.join(save_directory, f'Chapter_{chapter_number}.docx')\n",
    "    new_doc.save(chapter_filename)\n",
    "    print(f'Chapter {chapter_number} saved as {chapter_filename}')\n",
    "\n",
    "### 02_looking_for_appearance ###\n",
    "\n",
    "def search_words_in_chapter(chapter_text, words):\n",
    "    \"\"\"–ò—â–µ—Ç —Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–µ –≥–ª–∞–≤—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ö —Å –ø–æ–∑–∏—Ü–∏—è–º–∏.\"\"\"\n",
    "    word_pattern = r'\\b(' + '|'.join(re.escape(word) for word in words) + r')\\b'\n",
    "    matches = []\n",
    "\n",
    "    for match in re.finditer(word_pattern, chapter_text, re.IGNORECASE):\n",
    "        start, end = match.start(), match.end()\n",
    "\n",
    "        # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –≤–æ–∫—Ä—É–≥ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞\n",
    "        start_context = chapter_text[:start].split()[-8:]\n",
    "        end_context = chapter_text[end:].split()[:8]\n",
    "        found_word = chapter_text[start:end]\n",
    "        result = ' '.join(start_context + [found_word] + end_context)\n",
    "\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–∑–∏—Ü–∏—é –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "        matches.append((start, result))\n",
    "\n",
    "    return matches\n",
    "\n",
    "def search_in_all_chapters(chapters, words, category):\n",
    "    \"\"\"–ò—â–µ—Ç —Å–ª–æ–≤–∞ –≤–æ –≤—Å–µ—Ö –≥–ª–∞–≤–∞—Ö –∏ –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π.\"\"\"\n",
    "    total_matches = 0\n",
    "    results = []\n",
    "\n",
    "    for chapter_number, chapter_title, chapter_text in chapters:\n",
    "        matches = search_words_in_chapter(chapter_text, words)\n",
    "        total_matches += len(matches)\n",
    "\n",
    "        for position, match in matches:\n",
    "            results.append([chapter_number, chapter_title, position, match, category])\n",
    "\n",
    "    print(f\"‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è '{category}': –Ω–∞–π–¥–µ–Ω–æ {total_matches} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π.\")\n",
    "    return results\n",
    "\n",
    "def split_text_into_chapters(book_text):\n",
    "    \"\"\"–†–∞–∑–¥–µ–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –≥–ª–∞–≤—ã. –ü—Ä–∏–º–µ—Ä: —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–ª–æ–≤—É 'Chapter'.\"\"\"\n",
    "    chapters = []\n",
    "    chapter_texts = re.split(r'Chapter', book_text, flags=re.IGNORECASE)\n",
    "    for i, text in enumerate(chapter_texts[1:], start=1):\n",
    "        title_end = text.find('\\n')\n",
    "        chapter_title = text[:title_end].strip()\n",
    "        chapter_content = text[title_end + 1:].strip()\n",
    "        chapters.append((i, chapter_title, chapter_content))\n",
    "    return chapters\n",
    "\n",
    "def find_appearance(doc, path):\n",
    "\n",
    "    print(\"üìñ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞...\")\n",
    "\n",
    "    full_text = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        full_text.append(paragraph.text)\n",
    "        \n",
    "    book_text = '\\n'.join(full_text)\n",
    "\n",
    "    print(\"‚úÇÔ∏è –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –≥–ª–∞–≤—ã...\")\n",
    "    chapters = split_text_into_chapters(book_text)\n",
    "    if not chapters:\n",
    "        print(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –≥–ª–∞–≤—ã.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    all_results = []\n",
    "    for words, category in [\n",
    "        (clothes_words, 'Clothes'), (hair_words, 'Hair'),\n",
    "        (appearances_words, 'Appearances'), (weather_words, 'Weather'),\n",
    "        (locations_words, 'Locations'), (age_words, 'Age'), (other_words, 'Other')\n",
    "    ]:\n",
    "        all_results.extend(search_in_all_chapters(chapters, words, category))\n",
    "\n",
    "    print(\"üìä –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏...\")\n",
    "    all_data_df = pd.DataFrame(all_results, columns=['Chapter Number', 'Chapter Title', 'Position', 'Match', 'Category'])\n",
    "    \n",
    "    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É –≥–ª–∞–≤—ã –∏ –ø–æ–∑–∏—Ü–∏–∏\n",
    "    all_data_df.sort_values(by = ['Chapter Number', 'Position'], inplace = True)\n",
    "    # –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –ø–æ–∑–∏—Ü–∏—è–º–∏ —Å–ª–æ–≤–∞\n",
    "    all_data_df = all_data_df.drop(columns=['Position'])\n",
    "\n",
    "    print(\"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Excel...\")\n",
    "    os.makedirs(path, exist_ok = True)\n",
    "    excel_file_path = f\"{path}/Details_{path}.xlsx\"\n",
    "\n",
    "    try:\n",
    "        all_data_df.to_excel(excel_file_path, sheet_name='Appearance', index = False)\n",
    "        print(f\"‚úÖ –§–∞–π–ª Excel —Å–æ–∑–¥–∞–Ω: {excel_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ Excel —Ñ–∞–π–ª–∞: {e}\")\n",
    "\n",
    "def remove_inserts_and_format_headings(file_path, save_path):\n",
    "    # –û—Ç–∫—Ä—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç\n",
    "    doc = Document(file_path)\n",
    "\n",
    "    # –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤—Å—Ç–∞–≤–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å\n",
    "    patterns = [\n",
    "        r'\\d+o',  # –Ω–∞–ø—Ä–∏–º–µ—Ä, '4o'\n",
    "        r'–í—ã —Å–∫–∞–∑–∞–ª–∏:',  # –Ω–∞–ø—Ä–∏–º–µ—Ä, '–í—ã —Å–∫–∞–∑–∞–ª–∏:'\n",
    "        r'Chapter_\\d+\\.docx',  # –Ω–∞–ø—Ä–∏–º–µ—Ä, 'Chapter_2.docx', 'Chapter_3.docx'\n",
    "        r'–î–æ–∫—É–º–µ–Ω—Ç',  # –Ω–∞–ø—Ä–∏–º–µ—Ä, '–î–æ–∫—É–º–µ–Ω—Ç'\n",
    "        r'ChatGPT',  # –Ω–∞–ø—Ä–∏–º–µ—Ä, 'ChatGPT'\n",
    "        r'ChatGPT —Å–∫–∞–∑–∞–ª:',  # –Ω–∞–ø—Ä–∏–º–µ—Ä, 'ChatGPT —Å–∫–∞–∑–∞–ª'\n",
    "        r'^–≠—Ç–æ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –º–æ–∂–µ—Ç –Ω–∞—Ä—É—à–∞—Ç—å –Ω–∞—à—É –ø–æ–ª–∏—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\\.$',  # —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ñ—Ä–∞–∑—ã\n",
    "        r'^–ü–∞–º—è—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞$'  # —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ñ—Ä–∞–∑—ã\n",
    "    ]\n",
    "\n",
    "    # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≥–ª–∞–≤: –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≥–ª–∞–≤—ã + –Ω–æ–º–µ—Ä\n",
    "    chapter_heading_pattern = re.compile(r'^–ì–ª–∞–≤–∞\\s+\\d+')\n",
    "\n",
    "    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, –Ω—É–∂–Ω–æ –ª–∏ —É–¥–∞–ª—è—Ç—å –∞–±–∑–∞—Ü\n",
    "    def should_delete(paragraph):\n",
    "        for pattern in patterns:\n",
    "            if re.match(pattern, paragraph.text.strip()):  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –∞–±–∑–∞—Ü —Ü–µ–ª–∏–∫–æ–º —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —à–∞–±–ª–æ–Ω–æ–º\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
    "    new_doc = Document()\n",
    "\n",
    "    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∞–±–∑–∞—Ü–∞–º –∏ —É–¥–∞–ª—è–µ–º —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —à–∞–±–ª–æ–Ω–∞–º\n",
    "    for para in doc.paragraphs:\n",
    "        if not should_delete(para):\n",
    "            # –ï—Å–ª–∏ –∞–±–∑–∞—Ü —è–≤–ª—è–µ—Ç—Å—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –≥–ª–∞–≤—ã, –ø—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∏–ª—å \"–ó–∞–≥–æ–ª–æ–≤–æ–∫ 3\"\n",
    "            if chapter_heading_pattern.match(para.text.strip()):\n",
    "                new_doc.add_paragraph(para.text, style='Heading 3')\n",
    "            else:\n",
    "                # –î–æ–±–∞–≤–ª—è–µ–º –∞–±–∑–∞—Ü –≤ –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç, —Å–æ—Ö—Ä–∞–Ω—è—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "                new_para = new_doc.add_paragraph()\n",
    "                for run in para.runs:\n",
    "                    new_run = new_para.add_run(run.text)\n",
    "                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "                    new_run.bold = run.bold\n",
    "                    new_run.italic = run.italic\n",
    "                    new_run.underline = run.underline\n",
    "                    new_run.font.name = run.font.name\n",
    "                    new_run.font.size = run.font.size\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç\n",
    "    new_doc.save(save_path)\n",
    "\n",
    "    # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞\n",
    "    abs_path = os.path.abspath(save_path)\n",
    "    print(f\"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: {abs_path}\")\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "def clean_summary(docx_doc, path):\n",
    "    file_path = f\"{path}/summary.docx\"  # –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª\n",
    "    save_path = f\"{path}/summary_clean.docx\"  # –§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–µ–∑ –≤—Å—Ç–∞–≤–æ–∫\n",
    "    \n",
    "    remove_inserts_and_format_headings(file_path, save_path)\n",
    "\n",
    "\n",
    "##04_Cover##\n",
    "def extract_sections(doc, summary_label, location_label, character_label):\n",
    "    summaries = []\n",
    "    locations = []\n",
    "    characters = []\n",
    "    current_section = \"\"\n",
    "    section_type = None\n",
    "    \n",
    "    for paragraph in doc.paragraphs:\n",
    "        text = paragraph.text.strip()\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –º–µ—Ç–∫–æ–π —Ä–∞–∑–¥–µ–ª–∞\n",
    "        if summary_label in text or location_label in text or character_label in text:\n",
    "            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ä–∞–∑–¥–µ–ª –ø–µ—Ä–µ–¥ —Å–º–µ–Ω–æ–π —Ç–∏–ø–∞\n",
    "            if current_section:\n",
    "                if section_type == \"summary\":\n",
    "                    summaries.append(current_section.strip())\n",
    "                elif section_type == \"location\":\n",
    "                    locations.append(current_section.strip())\n",
    "                elif section_type == \"character\":\n",
    "                    characters.append(current_section.strip())\n",
    "            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ä–∞–∑–¥–µ–ª\n",
    "            current_section = \"\"\n",
    "            \n",
    "            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ–≤—ã–π —Ç–∏–ø —Ä–∞–∑–¥–µ–ª–∞\n",
    "            if summary_label in text:\n",
    "                section_type = \"summary\"\n",
    "            elif location_label in text:\n",
    "                section_type = \"location\"\n",
    "            elif character_label in text:\n",
    "                section_type = \"character\"\n",
    "            \n",
    "            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∞–º—É –º–µ—Ç–∫—É —Ä–∞–∑–¥–µ–ª–∞\n",
    "            \n",
    "        if text == \"\":\n",
    "            continue\n",
    "            \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –º–µ—Ç–∫–∞ —Ä–∞–∑–¥–µ–ª–∞\n",
    "        if section_type:\n",
    "            current_section += text + \" \"\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑–¥–µ–ª\n",
    "    if current_section:\n",
    "        if section_type == \"summary\":\n",
    "            summaries.append(current_section.strip())\n",
    "        elif section_type == \"location\":\n",
    "            locations.append(current_section.strip())\n",
    "        elif section_type == \"character\":\n",
    "            characters.append(current_section.strip())\n",
    "            \n",
    "    return summaries, locations, characters\n",
    "\n",
    "\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª—ã\n",
    "def save_to_docx(data, output_path, title_prefix):\n",
    "    doc = Document()\n",
    "    for idx, section in enumerate(data, start=1):\n",
    "        doc.add_heading(f\"{title_prefix} {idx}\", level=1)\n",
    "        doc.add_paragraph(section)\n",
    "    doc.save(output_path)\n",
    "    print(f\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}\")\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–ª–µ–Ω–∏—è summaries –Ω–∞ 3 —á–∞—Å—Ç–∏, –Ω–µ —Ä–∞–∑—Ä—ã–≤–∞—è –≥–ª–∞–≤—ã\n",
    "def split_summaries_evenly(summaries):\n",
    "    chunk_size = math.ceil(len(summaries) / 3)\n",
    "    chunks = []\n",
    "\n",
    "    start = 0\n",
    "    for i in range(3):\n",
    "        end = min(start + chunk_size, len(summaries))\n",
    "        chunks.append(summaries[start:end])\n",
    "        start = end\n",
    "\n",
    "    return chunks\n",
    "    \n",
    "def create_cover_info(docx_doc, path):\n",
    "    summary_label = \"–°–æ–±—ã—Ç–∏—è –≥–ª–∞–≤—ã:\"\n",
    "    location_label = \"–õ–æ–∫–∞—Ü–∏–∏ –≥–ª–∞–≤—ã:\"\n",
    "    character_label = \"–ü–µ—Ä—Å–æ–Ω–∞–∂–∏ –≥–ª–∞–≤—ã:\"\n",
    "    \n",
    "    output_path = path\n",
    "    summary = Document(f\"{output_path}/summary_clean.docx\")\n",
    "    summaries, locations, characters = extract_sections(summary, summary_label, location_label, character_label)\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã\n",
    "    save_to_docx(summaries, f\"{output_path}/synopsis.docx\", \"–°–æ–±—ã—Ç–∏—è –≥–ª–∞–≤—ã\")\n",
    "    save_to_docx(locations, f\"{output_path}/locations.docx\", \"–õ–æ–∫–∞—Ü–∏–∏ –≥–ª–∞–≤—ã\")\n",
    "    save_to_docx(characters, f\"{output_path}/characters.docx\", \"–ü–µ—Ä—Å–æ–Ω–∞–∂–∏ –≥–ª–∞–≤—ã\")\n",
    "\n",
    "    # –î–µ–ª–∏–º summaries –Ω–∞ 3 —á–∞—Å—Ç–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ö\n",
    "    chunks = split_summaries_evenly(summaries)\n",
    "    for i, chunk in enumerate(chunks, start=1):\n",
    "        save_to_docx(chunk, f\"{output_path}/summary_part_{i}.docx\", \"–ì–ª–∞–≤–∞\")\n",
    "\n",
    "    print(\"–§–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!\")\n",
    "\n",
    "##Extra: Fix Chapters##\n",
    "def fix_chapters(doc, path):\n",
    "    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º\n",
    "    for para in doc.paragraphs:\n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç—É \"2. Title\"\n",
    "        if re.match(r'^\\d+\\.\\s', para.text):\n",
    "            # –ó–∞–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç –Ω–∞ \"Chapter 2. Title\"\n",
    "            para.text = re.sub(r'^(\\d+)\\.\\s', r'Chapter \\1. ', para.text)\n",
    "\n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç—É \"2: Title\"\n",
    "        if re.match(r'^\\d+\\:\\s', para.text):\n",
    "            # –ó–∞–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç –Ω–∞ \"Chapter 2. Title\"\n",
    "            para.text = re.sub(r'^(\\d+):\\s', r'Chapter \\1. ', para.text)\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –Ω–æ–≤—ã–π —Ñ–∞–π–ª\n",
    "    current_path = path + '.docx'\n",
    "    new_file_path = current_path.replace('.docx', '_updated.docx')\n",
    "    doc.save(new_file_path)\n",
    "    print(f\"–ò–∑–º–µ–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª–µ: {new_file_path}\")\n",
    "    return new_file_path\n",
    "    \n",
    "\n",
    "##CUSTOM SUMMARY SPLITTING##\n",
    "def custom_split(path):\n",
    "    # –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ\n",
    "    path = path\n",
    "    print(\"–£–∫–∞–∂–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç—å —Ñ–∞–π–ª synopsis.docx\")\n",
    "    \n",
    "    def parse_ranges(ranges_input):\n",
    "        ranges = []\n",
    "        for r in ranges_input.split(','):\n",
    "            parts = r.strip().split('-')\n",
    "            if len(parts) == 2 and parts[0].isdigit() and parts[1].isdigit():\n",
    "                ranges.append((int(parts[0]), int(parts[1])))\n",
    "            elif len(parts) == 1 and parts[0].isdigit():\n",
    "                chapter = int(parts[0])\n",
    "                ranges.append((chapter, chapter))\n",
    "            else:\n",
    "                raise ValueError(f\"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∏–∞–ø–∞–∑–æ–Ω–∞: '{r}'. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–æ—Ä–º–∞—Ç '1-10, 11-13' –∏–ª–∏ '15'.\")\n",
    "        return ranges\n",
    "    \n",
    "    def split_docx_by_ranges(input_file, ranges, output_folder):\n",
    "        if not os.path.exists(input_file):\n",
    "            print(f\"–û—à–∏–±–∫–∞: –§–∞–π–ª '{input_file}' –Ω–µ –Ω–∞–π–¥–µ–Ω.\")\n",
    "            return\n",
    "    \n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "    \n",
    "        try:\n",
    "            doc = Document(input_file)\n",
    "            chapters = []\n",
    "            current_chapter = []\n",
    "            current_chapter_num = None\n",
    "    \n",
    "            # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–ª–∞–≤\n",
    "            for paragraph in doc.paragraphs:\n",
    "                text = paragraph.text.strip()\n",
    "                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –≥–ª–∞–≤—ã\n",
    "                if text.startswith(\"–°–æ–±—ã—Ç–∏—è –≥–ª–∞–≤—ã \"):\n",
    "                    try:\n",
    "                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –≥–ª–∞–≤—ã\n",
    "                        chapter_num = int(text.replace(\"–°–æ–±—ã—Ç–∏—è –≥–ª–∞–≤—ã \", \"\").strip())\n",
    "                        if current_chapter:\n",
    "                            chapters.append((current_chapter_num, current_chapter))\n",
    "                        current_chapter = [text]\n",
    "                        current_chapter_num = chapter_num\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                elif text:  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã\n",
    "                    if current_chapter_num is not None:\n",
    "                        current_chapter.append(text)\n",
    "    \n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≥–ª–∞–≤—É\n",
    "            if current_chapter:\n",
    "                chapters.append((current_chapter_num, current_chapter))\n",
    "    \n",
    "            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≥–ª–∞–≤—ã –ø–æ –Ω–æ–º–µ—Ä–∞–º\n",
    "            chapters.sort(key=lambda x: x[0])\n",
    "    \n",
    "            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞\n",
    "            for range_index, (start, end) in enumerate(ranges):\n",
    "                new_doc = Document()\n",
    "                relevant_chapters = [chapter for num, chapter in chapters if start <= num <= end]\n",
    "                \n",
    "                if relevant_chapters:\n",
    "                    for chapter_content in relevant_chapters:\n",
    "                        for paragraph in chapter_content:\n",
    "                            new_doc.add_paragraph(paragraph)\n",
    "                    \n",
    "                    file_path = f'{output_folder}/synopsis_part_{range_index + 1}_chapters_{start}_{end}.docx'\n",
    "                    new_doc.save(file_path)\n",
    "                    print(f\"–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª: {file_path}\")\n",
    "                else:\n",
    "                    print(f\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ì–ª–∞–≤—ã –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ {start}-{end} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}\")\n",
    "    \n",
    "    # –í–∏–¥–∂–µ—Ç—ã –¥–ª—è –≤–≤–æ–¥–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤\n",
    "    ranges_text = widgets.Text(\n",
    "        description='–î–∏–∞–ø–∞–∑–æ–Ω—ã:',\n",
    "        placeholder='–ü—Ä–∏–º–µ—Ä: 1-10, 11-13, 14-20, 21'\n",
    "    )\n",
    "    button = widgets.Button(description='–†–∞–∑–¥–µ–ª–∏—Ç—å —Ñ–∞–π–ª')\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_button_click(b):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            input_file = os.path.join(path, 'synopsis.docx')\n",
    "            output_folder = os.path.join(path, 'synopsis_parts')\n",
    "            if not os.path.exists(input_file):\n",
    "                print(f\"–û—à–∏–±–∫–∞: –§–∞–π–ª '{input_file}' –Ω–µ –Ω–∞–π–¥–µ–Ω.\")\n",
    "                return\n",
    "            ranges_input = ranges_text.value\n",
    "            try:\n",
    "                ranges = parse_ranges(ranges_input)\n",
    "                split_docx_by_ranges(input_file, ranges, output_folder)\n",
    "            except ValueError as ve:\n",
    "                print(f\"–û—à–∏–±–∫–∞: {ve}\")\n",
    "            except Exception as e:\n",
    "                print(f\"–û—à–∏–±–∫–∞: {e}\")\n",
    "    \n",
    "    button.on_click(on_button_click)\n",
    "    display(ranges_text, button, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4b7a2-f625-4a57-a66d-f6b26a793e29",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–º–ø—Ç—ã"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9db8b2a0-da0d-4bfb-ab06-32c46b30c537",
   "metadata": {},
   "source": [
    "–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6fb0c44d-12f0-471f-a9b7-b9583639e604",
   "metadata": {},
   "source": [
    "–í —ç—Ç–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ –∫—Ä–∞—Ç–∫–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –≥–ª–∞–≤ —Ä–æ–º–∞–Ω–∞. –ü–µ—Ä–µ—Å–∫–∞–∂–∏ —Å–æ–±—ã—Ç–∏—è —Ä–æ–º–∞–Ω–∞ –≤ 5-10 –∞–±–∑–∞—Ü–∞—Ö. \n",
    "–ü–µ—Ä–µ—Å–∫–∞–∑ –¥–æ–ª–∂–µ–Ω –æ—Ö–≤–∞—Ç—ã–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏—è –≤—Å–µ—Ö –≥–ª–∞–≤ –æ—Ç –Ω–∞—á–∞–ª–∞ –¥–æ –∫–æ–Ω—Ü–∞, —á—Ç–æ–±—ã –Ω–µ–∑–Ω–∞–∫–æ–º—ã–π —Å —Å—é–∂–µ—Ç–æ–º —á–µ–ª–æ–≤–µ–∫ –ø–æ–Ω—è–ª –æ—Å–Ω–æ–≤–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è –∏ —Ñ–∏–Ω–∞–ª."
   ]
  },
  {
   "cell_type": "raw",
   "id": "066ad8a9-7fa4-4dcd-867b-822c4254c868",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π –ø–µ—Ä–µ—Å–∫–∞–∂–µ–º –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ. –ü—Ä–∏—Å—ã–ª–∞—é –ø–µ—Ä–≤—ã–µ –•–• –≥–ª–∞–≤ –∏–∑ –•–•–•. –ü–µ—Ä–µ—Å–∫–∞–∂–∏ –∏—Ö –≤ 2-3 –∞–±–∑–∞—Ü–∞—Ö."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c82357fa-bcfc-4f2e-8e79-9e74b0d35d95",
   "metadata": {},
   "source": [
    "–ù–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –æ–ø–∏—à–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —Ä–æ–º–∞–Ω–∞. –û—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω—ã –¥–µ—Ç–∞–ª–∏ –≤–Ω–µ—à–Ω–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8dadac32-ba86-4da7-a327-f76f286852ea",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –æ–ø–∏—à–∏ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e23dd093-75cf-4bd6-868a-7fc46be78897",
   "metadata": {},
   "source": [
    "–ù–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –æ–ø–∏—à–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –ª–æ–∫–∞—Ü–∏–∏ —Ä–æ–º–∞–Ω–∞."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c279b73-c480-4577-b631-b4a0cf3d13aa",
   "metadata": {},
   "source": [
    "–û–ø–∏—à–∏ –ª–æ—Ä –∏ —Å–µ—Ç—Ç–∏–Ω–≥ —Ä–æ–º–∞–Ω–∞"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26f7f7ec-edd9-4f6c-9c9e-620f18b45eb3",
   "metadata": {},
   "source": [
    "–û–ø–∏—à–∏ –∂–∞–Ω—Ä –∏ —Ü–µ–ª–µ–≤—É—é –∞—É–¥–∏—Ç–æ—Ä–∏—é —Ä–æ–º–∞–Ω–∞"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2258370d-3e14-424a-8d4a-16ae84bc4cf6",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–¥—É–º–∞–π –∏ –æ–ø–∏—à–∏ 5 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ–±–ª–æ–∂–∫–∏ —Ä–æ–º–∞–Ω–∞ —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ —á—É–≤—Å—Ç–≤–∞ –∏ —Å—Ç—Ä–∞—Å—Ç—å –º–µ–∂–¥—É –≥–ª–∞–≤–Ω—ã–º–∏ –≥–µ—Ä–æ—è–º–∏"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
