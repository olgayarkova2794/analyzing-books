{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e426adf8-4904-4ff5-80ce-a5a576781ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f445c00d034a089758ff067bbe6474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.docx', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4640ad83ea4340fbb0351b06e1859776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Check', style=ButtonStyle(), tooltip='Check')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489c81cbd5c74813ae38c20f02962a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Split', style=ButtonStyle(), tooltip='Split')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3e888dd7cb43febf78a877493be40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Find Appearance', style=ButtonStyle(), tooltip='Find Appearance')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2244e027f77d404dadbc191edf2c9abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Clean summary', style=ButtonStyle(), tooltip='Clean summary')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ceae33ad18e4df8972eaffd3b74e83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Create cover file', style=ButtonStyle(), tooltip='Create cover file')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddb34d359804e17a34f5abed9fe4851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##PROMPT##\n",
    "\n",
    "##Прочитай текст следующей главы и сделай для нее краткое содержание на русском. \n",
    "##Краткое содержание должно включать заголовок и номер главы; события главы в 2-3 абзацах (заголовок События главы); \n",
    "##список персонажей, участвующих в главе, с описанием их внешнего вида - возраст, кожа, волосы, глаза, рост, одежда, поза и так далее, если указано (Персонажи главы); \n",
    "##список локаций главы и их описание, если указано (Локации главы); погода и время дня, если указано (Погода и время дня). Избегай предположений. Use temperature = 0.3##\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "import pythoncom\n",
    "import math\n",
    "from win32com import client as win32\n",
    "\n",
    "from IPython.display import display\n",
    "from docx import Document\n",
    "from collections import defaultdict\n",
    "from words import (\n",
    "    clothes_words, hair_words, appearances_words, weather_words,\n",
    "    locations_words, age_words, other_words\n",
    ")\n",
    "\n",
    "\n",
    "# Создаем виджет для загрузки файла\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept = '.docx',  # Принимаем только файлы .docx\n",
    "    multiple = False  # Только один файл\n",
    ")\n",
    "\n",
    "# Создаем кнопки\n",
    "analyze_button = widgets.Button(\n",
    "    description = 'Check',\n",
    "    disabled = False,\n",
    "    button_style = '',  # 'success', 'info', 'warning', 'danger' или ''\n",
    "    tooltip = 'Check',\n",
    "    icon = ''  # Иконка (имя FontAwesome без префикса `fa-`)\n",
    ")\n",
    "\n",
    "split_by_chapters_button = widgets.Button(\n",
    "    description = 'Split',\n",
    "    disabled = False,\n",
    "    button_style = '',  # 'success', 'info', 'warning', 'danger' или ''\n",
    "    tooltip = 'Split',\n",
    "    icon = ''  # Иконка (имя FontAwesome без префикса `fa-`)\n",
    ")\n",
    "\n",
    "find_appearance_button = widgets.Button(\n",
    "    description = 'Find Appearance',\n",
    "    disabled = False,\n",
    "    button_style = '',  # 'success', 'info', 'warning', 'danger' или ''\n",
    "    tooltip = 'Find Appearance',\n",
    "    icon = ''  # Иконка (имя FontAwesome без префикса `fa-`)\n",
    ")\n",
    "\n",
    "clean_summary_button = widgets.Button(\n",
    "    description = 'Clean summary',\n",
    "    disabled = False,\n",
    "    button_style = '',  # 'success', 'info', 'warning', 'danger' или ''\n",
    "    tooltip = 'Clean summary',\n",
    "    icon = ''  # Иконка (имя FontAwesome без префикса `fa-`)\n",
    ")\n",
    "\n",
    "cover_info_button = widgets.Button(\n",
    "    description = 'Create cover file',\n",
    "    disabled = False,\n",
    "    button_style = '',  # 'success', 'info', 'warning', 'danger' или ''\n",
    "    tooltip = 'Create cover file',\n",
    "    icon = ''  # Иконка (имя FontAwesome без префикса `fa-`)\n",
    ")\n",
    "\n",
    "# Создаем виджет вывода\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def convert_docm_to_docx(input_path, output_path):\n",
    "    \"\"\"Конвертирует файл .docm в .docx с помощью Microsoft Word.\"\"\"\n",
    "    try:\n",
    "        pythoncom.CoInitialize()\n",
    "        word = win32.Dispatch(\"Word.Application\")\n",
    "        word.Visible = False  # Запуск Word в фоновом режиме\n",
    "\n",
    "        print(f\"Конвертация {input_path} в {output_path}...\")\n",
    "        doc = word.Documents.Open(input_path)\n",
    "        doc.SaveAs(output_path, FileFormat=16)  # 16 — это формат для .docx\n",
    "        doc.Close()\n",
    "        word.Quit()\n",
    "        print(f\"Файл успешно конвертирован: {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при конвертации: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        pythoncom.CoUninitialize()\n",
    "\n",
    "\n",
    "def is_valid_docx(file_content):\n",
    "    \"\"\"Проверяет, можно ли открыть файл как документ Word.\"\"\"\n",
    "    try:\n",
    "        docx_file = io.BytesIO(file_content)\n",
    "        Document(docx_file)  # Попытка открыть как .docx\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def load_docx_file(file_info):\n",
    "    try:\n",
    "        filename = file_info['name']\n",
    "        file_content = file_info['content']\n",
    "\n",
    "        if not is_valid_docx(file_content):\n",
    "            print(f\"Ошибка: Файл {filename} повреждён или не является корректным .docx/.docm.\")\n",
    "            return None  # Добавляем return здесь, чтобы завершить выполнение\n",
    "\n",
    "        # Проверяем расширение и обрабатываем файл .docm\n",
    "        if filename.endswith('.docm'):\n",
    "            print(\"Обнаружен .docm файл, выполняется конвертация...\")\n",
    "            temp_docm_path = \"temp_file.docm\"\n",
    "            with open(temp_docm_path, 'wb') as f:\n",
    "                f.write(file_content)\n",
    "\n",
    "            temp_docx_path = \"temp_file.docx\"\n",
    "            if convert_docm_to_docx(temp_docm_path, temp_docx_path):\n",
    "                print(\"Загрузка сконвертированного .docx файла...\")\n",
    "                with open(temp_docx_path, 'rb') as f:\n",
    "                    docx_file = io.BytesIO(f.read())\n",
    "\n",
    "                # Удаление временных файлов\n",
    "                os.remove(temp_docm_path)\n",
    "                os.remove(temp_docx_path)\n",
    "            else:\n",
    "                print(\"Конвертация не удалась.\")\n",
    "                return None\n",
    "        else:\n",
    "            print(\"Загружается файл .docx...\")\n",
    "            docx_file = io.BytesIO(file_content)\n",
    "\n",
    "        # Пытаемся открыть документ Word\n",
    "        docx = Document(docx_file)\n",
    "        print(\"Файл успешно загружен и прочитан.\")\n",
    "        return docx\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке файла: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# Функции для обработки нажатия кнопок\n",
    "def on_analyze_button_click(event):\n",
    "    with output:\n",
    "        output.clear_output()  # Очищаем предыдущий вывод\n",
    "        if upload_widget.value:\n",
    "            # Получаем первый элемент кортежа (информацию о загруженном файле)\n",
    "            file_info = list(upload_widget.value)[0]\n",
    "            filename = file_info['name']  # Извлекаем имя файла\n",
    "            print(f'Загруженный файл: {filename}')\n",
    "            \n",
    "            docx_doc = load_docx_file(file_info)\n",
    "            analyze_book(docx_doc)\n",
    "        else:\n",
    "            print(\"Файл не загружен\")\n",
    "\n",
    "def on_split_by_chapters_button_click(event):\n",
    "    with output:\n",
    "        output.clear_output()  # Очищаем предыдущий вывод\n",
    "        if upload_widget.value:\n",
    "            # Получаем первый элемент кортежа (информацию о загруженном файле)\n",
    "            file_info = list(upload_widget.value)[0]\n",
    "            filename = file_info['name']  # Извлекаем имя файла\n",
    "            \n",
    "            print(f'Загруженный файл: {filename}')\n",
    "\n",
    "            path = os.path.splitext(filename)[0]\n",
    "            docx_doc = load_docx_file(file_info)\n",
    "            \n",
    "            split_chapters(docx_doc, path)\n",
    "        else:\n",
    "            print(\"Файл не загружен\")\n",
    "\n",
    "def on_find_appearance_button_click(event):\n",
    "    with output:\n",
    "        output.clear_output()  # Очищаем предыдущий вывод\n",
    "        if upload_widget.value:\n",
    "            # Получаем первый элемент кортежа (информацию о загруженном файле)\n",
    "            file_info = list(upload_widget.value)[0]\n",
    "            filename = file_info['name']  # Извлекаем имя файла\n",
    "            \n",
    "            print(f'Загруженный файл: {filename}')\n",
    "\n",
    "            path = os.path.splitext(filename)[0]\n",
    "            docx_doc = load_docx_file(file_info)\n",
    "            \n",
    "            find_appearance(docx_doc, path)\n",
    "        else:\n",
    "            print(\"Файл не загружен\")\n",
    "\n",
    "def on_clean_summary_button_click(event):\n",
    "    with output:\n",
    "        output.clear_output()  # Очищаем предыдущий вывод\n",
    "        if upload_widget.value:\n",
    "            # Получаем первый элемент кортежа (информацию о загруженном файле)\n",
    "            file_info = list(upload_widget.value)[0]\n",
    "            filename = file_info['name']  # Извлекаем имя файла\n",
    "            \n",
    "            print(f'Загруженный файл: {filename}')\n",
    "\n",
    "            path = os.path.splitext(filename)[0]\n",
    "            docx_doc = load_docx_file(file_info)\n",
    "            \n",
    "            clean_summary(docx_doc, path)\n",
    "        else:\n",
    "            print(\"Файл не загружен\")\n",
    "\n",
    "def on_cover_info_button_click(event):\n",
    "    with output:\n",
    "        output.clear_output()  # Очищаем предыдущий вывод\n",
    "        if upload_widget.value:\n",
    "            # Получаем первый элемент кортежа (информацию о загруженном файле)\n",
    "            file_info = list(upload_widget.value)[0]\n",
    "            filename = file_info['name']  # Извлекаем имя файла\n",
    "            \n",
    "            print(f'Загруженный файл: {filename}')\n",
    "\n",
    "            path = os.path.splitext(filename)[0]\n",
    "            docx_doc = load_docx_file(file_info)\n",
    "            \n",
    "            create_cover_info(docx_doc, path)\n",
    "        else:\n",
    "            print(\"Файл не загружен\")\n",
    "            \n",
    "\n",
    "# Привязываем функции к кнопке\n",
    "analyze_button.on_click(on_analyze_button_click)\n",
    "split_by_chapters_button.on_click(on_split_by_chapters_button_click)\n",
    "find_appearance_button.on_click(on_find_appearance_button_click)\n",
    "clean_summary_button.on_click(on_clean_summary_button_click)\n",
    "cover_info_button.on_click(on_cover_info_button_click)\n",
    "\n",
    "# Отображаем виджеты\n",
    "display(upload_widget, analyze_button, split_by_chapters_button, find_appearance_button, clean_summary_button, cover_info_button, output)\n",
    "\n",
    "# Словарь для преобразования чисел из текстового формата\n",
    "TEXT_NUMBERS = {\n",
    "    'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6,\n",
    "    'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10, 'eleven': 11, 'twelve': 12,\n",
    "    'thirteen': 13, 'fourteen': 14, 'fifteen': 15, 'sixteen': 16,\n",
    "    'seventeen': 17, 'eighteen': 18, 'nineteen': 19, 'twenty': 20,\n",
    "    'thirty': 30, 'forty': 40, 'fifty': 50, 'sixty': 60, 'seventy': 70,\n",
    "    'eighty': 80, 'ninety': 90, 'hundred': 100\n",
    "}\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "### 00_book_Check ###\n",
    "\n",
    "def word_to_number(word):\n",
    "    \"\"\"Преобразует текстовое число в числовое значение.\"\"\"\n",
    "    words = re.split(r'[\\s\\-]+', word.lower())  # Разбиваем по пробелам и дефисам\n",
    "    number = 0\n",
    "    temp = 0\n",
    "\n",
    "    for w in words:\n",
    "        if w in TEXT_NUMBERS:\n",
    "            scale = TEXT_NUMBERS[w]\n",
    "            if scale == 100:  # Обработка сотен, например \"one hundred\"\n",
    "                temp *= scale\n",
    "            else:\n",
    "                temp += scale\n",
    "        else:\n",
    "            return None  # Если слово не распознано, возвращаем None\n",
    "\n",
    "    number += temp\n",
    "    return number\n",
    "\n",
    "def extract_chapter_number(text):\n",
    "    \"\"\"Извлекает номер главы из текста.\"\"\"\n",
    "    # Проверяем числовой формат, например, \"Chapter 1\" или \"Chapter 1 - School Trouble\"\n",
    "    numeric_match = re.match(r'Chapter\\s+(\\d+)', text, re.IGNORECASE)\n",
    "    if numeric_match:\n",
    "        return int(numeric_match.group(1))\n",
    "    \n",
    "    # Проверяем текстовый формат, например, \"Chapter One\" или \"Chapter Thirty-one\"\n",
    "    text_match = re.match(r'Chapter\\s+([\\w\\s\\-]+)', text, re.IGNORECASE)\n",
    "    if text_match:\n",
    "        word = text_match.group(1).strip()\n",
    "        return word_to_number(word)\n",
    "    return None\n",
    "\n",
    "def extract_chapters(doc):\n",
    "    \"\"\"Извлекает главы и их содержимое из .docx файла.\"\"\"\n",
    "    chapters = []\n",
    "    current_chapter = None\n",
    "    current_text = []\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        chapter_num = extract_chapter_number(para.text.strip())\n",
    "        if chapter_num is not None:\n",
    "            if current_chapter is not None and current_text:\n",
    "                chapters.append((current_chapter, \"\\n\".join(current_text).strip()))\n",
    "            current_chapter = chapter_num\n",
    "            current_text = []\n",
    "        else:\n",
    "            current_text.append(para.text.strip())\n",
    "\n",
    "    if current_chapter is not None and current_text:\n",
    "        chapters.append((current_chapter, \"\\n\".join(current_text).strip()))\n",
    "\n",
    "    return chapters\n",
    "\n",
    "def check_duplicate_chapters(chapters):\n",
    "    chapter_numbers = [chap[0] for chap in chapters]\n",
    "    return {chap for chap in chapter_numbers if chapter_numbers.count(chap) > 1}\n",
    "\n",
    "def check_text_duplicates(chapters):\n",
    "    \"\"\"Проверяет дублирующийся текст в главах с учётом нормализации.\"\"\"\n",
    "    text_to_chapter = defaultdict(list)\n",
    "\n",
    "    for chapter, text in chapters:\n",
    "        # Нормализуем текст: убираем лишние пробелы и приводим к нижнему регистру\n",
    "        normalized_text = \" \".join(text.split()).lower()\n",
    "        \n",
    "        # Добавляем номер главы в список глав с таким же текстом\n",
    "        text_to_chapter[normalized_text].append(chapter)\n",
    "\n",
    "    # Фильтруем только те записи, где один и тот же текст встречается более одного раза\n",
    "    return {text: chaps for text, chaps in text_to_chapter.items() if len(chaps) > 1}\n",
    "\n",
    "def check_chapter_order(chapters):\n",
    "    chapter_numbers = [chap[0] for chap in chapters]\n",
    "    return [(chapter_numbers[i], chapter_numbers[i+1]) \n",
    "            for i in range(len(chapter_numbers) - 1) if chapter_numbers[i] > chapter_numbers[i + 1]]\n",
    "\n",
    "def check_missing_chapters(chapters):\n",
    "    \"\"\"Проверяет пропущенные главы в последовательности.\"\"\"\n",
    "    chapter_numbers = sorted([chap[0] for chap in chapters])\n",
    "    missing_chapters = [num for num in range(chapter_numbers[0], chapter_numbers[-1] + 1) \n",
    "                        if num not in chapter_numbers]\n",
    "    return missing_chapters\n",
    "\n",
    "def analyze_book(docx_file):\n",
    "    chapters = extract_chapters(docx_file)\n",
    "\n",
    "    print(\"Список найденных глав:\")\n",
    "    for chapter, text in chapters:\n",
    "        print(f\"Chapter {chapter}: {text[:50]}...\")\n",
    "    \n",
    "    duplicate_chapters = check_duplicate_chapters(chapters)\n",
    "    duplicate_texts = check_text_duplicates(chapters)\n",
    "    unordered_chapters = check_chapter_order(chapters)\n",
    "    missing_chapters = check_missing_chapters(chapters)\n",
    "\n",
    "    print(\"\\nРезультаты проверок:\")\n",
    "    print(f\"❌ Найдены повторяющиеся главы: {duplicate_chapters}\" if duplicate_chapters else \"✅ Повторяющиеся главы не найдены.\")\n",
    "    print(f\"❌ Найдены главы с дублирующимся текстом: {duplicate_texts}\" if duplicate_texts else \"✅ Дублирующийся текст не найден.\")\n",
    "    print(f\"❌ Найдены главы с нарушением порядка: {unordered_chapters}\" if unordered_chapters else \"✅ Нарушений в порядке глав не обнаружено.\")\n",
    "    print(f\"❌ Пропущенные главы: {missing_chapters}\" if missing_chapters else \"✅ Пропущенных глав не найдено.\")\n",
    "\n",
    "\n",
    "\n",
    "### 01_Breaking_into_chapters ###\n",
    "\n",
    "def split_chapters(doc, path):\n",
    "    #print('split_chapters(doc_path in doc.paragraph)')\n",
    "    # Буфер для накопления содержимого текущей главы\n",
    "    current_chapter = []\n",
    "    chapter_number = 0\n",
    "\n",
    "    # Регулярное выражение для поиска заголовков глав, включая дефис\n",
    "    chapter_pattern = re.compile('Chapter', re.IGNORECASE)\n",
    "    found_first_chapter = False  # Флаг для пропуска текста до первой главы\n",
    "\n",
    "    # Проходим по параграфам документа\n",
    "    for paragraph in doc.paragraphs:\n",
    "        # Если параграф соответствует заголовку главы\n",
    "        if chapter_pattern.match(paragraph.text.strip()):\n",
    "            if found_first_chapter and current_chapter:\n",
    "                save_chapter(current_chapter, chapter_number, path)\n",
    "\n",
    "            # Очищаем буфер для новой главы и увеличиваем номер главы\n",
    "            current_chapter = [paragraph.text]\n",
    "            chapter_number += 1\n",
    "            found_first_chapter = True  # Первая глава найдена\n",
    "        else:\n",
    "            # Добавляем содержимое параграфа в текущую главу, только если первая глава уже найдена\n",
    "            if found_first_chapter:\n",
    "                current_chapter.append(paragraph.text)\n",
    "\n",
    "    # Сохраняем последнюю главу\n",
    "    if current_chapter:\n",
    "        save_chapter(current_chapter, chapter_number, path)\n",
    "\n",
    "def save_chapter(chapter_content, chapter_number, path):\n",
    "    print('save')\n",
    "    # Создаем новый документ для главы\n",
    "    new_doc = Document()\n",
    "    \n",
    "    # Добавляем содержимое главы в новый документ\n",
    "    for paragraph in chapter_content:\n",
    "        new_doc.add_paragraph(paragraph)\n",
    "    \n",
    "    # Указываем папку для сохранения\n",
    "    save_directory = f'{path}'  # замените на нужный путь\n",
    "    \n",
    "    # Убедимся, что папка существует, если нет — создаем\n",
    "    os.makedirs(save_directory, exist_ok = True)\n",
    "    \n",
    "    # Сохраняем документ с названием Chapter_N.docx в указанную папку\n",
    "    chapter_filename = os.path.join(save_directory, f'Chapter_{chapter_number}.docx')\n",
    "    new_doc.save(chapter_filename)\n",
    "    print(f'Chapter {chapter_number} saved as {chapter_filename}')\n",
    "\n",
    "\n",
    "\n",
    "### 02_looking_for_appearance ###\n",
    "\n",
    "def search_words_in_chapter(chapter_text, words):\n",
    "    \"\"\"Ищет слова в тексте главы и возвращает их с позициями.\"\"\"\n",
    "    word_pattern = r'\\b(' + '|'.join(re.escape(word) for word in words) + r')\\b'\n",
    "    matches = []\n",
    "\n",
    "    for match in re.finditer(word_pattern, chapter_text, re.IGNORECASE):\n",
    "        start, end = match.start(), match.end()\n",
    "\n",
    "        # Собираем контексты вокруг найденного слова\n",
    "        start_context = chapter_text[:start].split()[-8:]\n",
    "        end_context = chapter_text[end:].split()[:8]\n",
    "        found_word = chapter_text[start:end]\n",
    "        result = ' '.join(start_context + [found_word] + end_context)\n",
    "\n",
    "        # Сохраняем позицию и результат\n",
    "        matches.append((start, result))\n",
    "\n",
    "    return matches\n",
    "\n",
    "def search_in_all_chapters(chapters, words, category):\n",
    "    \"\"\"Ищет слова во всех главах и подсчитывает общее количество совпадений.\"\"\"\n",
    "    total_matches = 0\n",
    "    results = []\n",
    "\n",
    "    for chapter_number, chapter_title, chapter_text in chapters:\n",
    "        matches = search_words_in_chapter(chapter_text, words)\n",
    "        total_matches += len(matches)\n",
    "\n",
    "        for position, match in matches:\n",
    "            results.append([chapter_number, chapter_title, position, match, category])\n",
    "\n",
    "    print(f\"✅ Категория '{category}': найдено {total_matches} совпадений.\")\n",
    "    return results\n",
    "\n",
    "def split_text_into_chapters(book_text):\n",
    "    \"\"\"Разделяет текст на главы. Пример: разделение по слову 'Chapter'.\"\"\"\n",
    "    chapters = []\n",
    "    chapter_texts = re.split(r'Chapter', book_text, flags=re.IGNORECASE)\n",
    "    for i, text in enumerate(chapter_texts[1:], start=1):\n",
    "        title_end = text.find('\\n')\n",
    "        chapter_title = text[:title_end].strip()\n",
    "        chapter_content = text[title_end + 1:].strip()\n",
    "        chapters.append((i, chapter_title, chapter_content))\n",
    "    return chapters\n",
    "\n",
    "def find_appearance(doc, path):\n",
    "\n",
    "    print(\"📖 Извлечение текста из файла...\")\n",
    "\n",
    "    full_text = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        full_text.append(paragraph.text)\n",
    "        \n",
    "    book_text = '\\n'.join(full_text)\n",
    "\n",
    "    print(\"✂️ Разделение текста на главы...\")\n",
    "    chapters = split_text_into_chapters(book_text)\n",
    "    if not chapters:\n",
    "        print(\"❌ Не удалось разделить текст на главы.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    all_results = []\n",
    "    for words, category in [\n",
    "        (clothes_words, 'Clothes'), (hair_words, 'Hair'),\n",
    "        (appearances_words, 'Appearances'), (weather_words, 'Weather'),\n",
    "        (locations_words, 'Locations'), (age_words, 'Age'), (other_words, 'Other')\n",
    "    ]:\n",
    "        all_results.extend(search_in_all_chapters(chapters, words, category))\n",
    "\n",
    "    print(\"📊 Создание DataFrame с результатами...\")\n",
    "    all_data_df = pd.DataFrame(all_results, columns=['Chapter Number', 'Chapter Title', 'Position', 'Match', 'Category'])\n",
    "    \n",
    "    # Сортируем по номеру главы и позиции\n",
    "    all_data_df.sort_values(by = ['Chapter Number', 'Position'], inplace = True)\n",
    "    # Удаляем колонку с позициями слова\n",
    "    all_data_df = all_data_df.drop(columns=['Position'])\n",
    "\n",
    "    print(\"💾 Сохранение результатов в Excel...\")\n",
    "    os.makedirs(path, exist_ok = True)\n",
    "    excel_file_path = f\"{path}/Details.xlsx\"\n",
    "\n",
    "    try:\n",
    "        all_data_df.to_excel(excel_file_path, sheet_name='Appearance', index = False)\n",
    "        print(f\"✅ Файл Excel создан: {excel_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка при сохранении Excel файла: {e}\")\n",
    "\n",
    "##03_clean_summary##\n",
    "def remove_inserts_and_format_headings(file_path, save_path):\n",
    "    # Открываем документ\n",
    "    doc = Document(file_path)\n",
    "\n",
    "    # Регулярные выражения для поиска вставок, которые нужно удалить\n",
    "    patterns = [\n",
    "        r'\\d+o',  # например, '4o'\n",
    "        r'Вы сказали:',  # например, 'Вы сказали:'\n",
    "        r'Chapter_\\d+\\.docx',  # например, 'Chapter_2.docx', 'Chapter_3.docx'\n",
    "        r'Документ',  # например, 'Документ'\n",
    "        r'ChatGPT',  # например, 'ChatGPT'\n",
    "        r'^Этот контент может нарушать нашу политику использования\\.$',  # точное совпадение фразы\n",
    "        r'^Память обновлена$'  # точное совпадение фразы\n",
    "    ]\n",
    "\n",
    "    # Регулярное выражение для заголовков глав: Краткое содержание главы + номер\n",
    "    chapter_heading_pattern = re.compile(r'^Глава\\s+\\d+')\n",
    "\n",
    "    # Функция для проверки, нужно ли удалять абзац\n",
    "    def should_delete(paragraph):\n",
    "        for pattern in patterns:\n",
    "            if re.match(pattern, paragraph.text.strip()):  # Только если абзац целиком совпадает с шаблоном\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # Создаем новый документ для сохранения изменений\n",
    "    new_doc = Document()\n",
    "\n",
    "    # Проходим по абзацам и удаляем те, которые соответствуют шаблонам\n",
    "    for para in doc.paragraphs:\n",
    "        if not should_delete(para):\n",
    "            # Если абзац является заголовком главы, применяем стиль \"Заголовок 3\"\n",
    "            if chapter_heading_pattern.match(para.text.strip()):\n",
    "                new_doc.add_paragraph(para.text, style='Heading 3')\n",
    "            else:\n",
    "                # Добавляем абзац в новый документ, сохраняя форматирование\n",
    "                new_para = new_doc.add_paragraph()\n",
    "                for run in para.runs:\n",
    "                    new_run = new_para.add_run(run.text)\n",
    "                    # Сохраняем форматирование\n",
    "                    new_run.bold = run.bold\n",
    "                    new_run.italic = run.italic\n",
    "                    new_run.underline = run.underline\n",
    "                    new_run.font.name = run.font.name\n",
    "                    new_run.font.size = run.font.size\n",
    "\n",
    "    # Сохраняем новый документ\n",
    "    new_doc.save(save_path)\n",
    "\n",
    "    # Уведомление о сохранении файла\n",
    "    abs_path = os.path.abspath(save_path)\n",
    "    print(f\"Файл успешно сохранен по адресу: {abs_path}\")\n",
    "\n",
    "# Пример использования\n",
    "def clean_summary(docx_doc, path):\n",
    "    file_path = f\"{path}/summary.docx\"  # Исходный файл\n",
    "    save_path = f\"{path}/summary_clean.docx\"  # Файл для сохранения без вставок\n",
    "    \n",
    "    remove_inserts_and_format_headings(file_path, save_path)\n",
    "\n",
    "\n",
    "\n",
    "##04_Cover##\n",
    "def extract_sections(doc, summary_label, location_label, character_label):\n",
    "    summaries = []\n",
    "    locations = []\n",
    "    characters = []\n",
    "\n",
    "    current_section = \"\"\n",
    "    section_type = None\n",
    "\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text = paragraph.text.strip()\n",
    "\n",
    "        if summary_label in text:\n",
    "            if current_section:\n",
    "                if section_type == \"location\":\n",
    "                    locations.append(current_section.strip())\n",
    "                elif section_type == \"character\":\n",
    "                    characters.append(current_section.strip())\n",
    "            section_type = \"summary\"\n",
    "            current_section = \"\"\n",
    "\n",
    "        elif location_label in text:\n",
    "            if current_section:\n",
    "                if section_type == \"summary\":\n",
    "                    summaries.append(current_section.strip())\n",
    "                elif section_type == \"character\":\n",
    "                    characters.append(current_section.strip())\n",
    "            section_type = \"location\"\n",
    "            current_section = \"\"\n",
    "\n",
    "        elif character_label in text:\n",
    "            if current_section:\n",
    "                if section_type == \"summary\":\n",
    "                    summaries.append(current_section.strip())\n",
    "                elif section_type == \"location\":\n",
    "                    locations.append(current_section.strip())\n",
    "            section_type = \"character\"\n",
    "            current_section = \"\"\n",
    "\n",
    "        elif text == \"\":\n",
    "            continue\n",
    "\n",
    "        if section_type == \"summary\":\n",
    "            current_section += text + \" \"\n",
    "        elif section_type == \"location\":\n",
    "            current_section += text + \" \"\n",
    "        elif section_type == \"character\":\n",
    "            current_section += text + \" \"\n",
    "\n",
    "    if current_section:\n",
    "        if section_type == \"summary\":\n",
    "            summaries.append(current_section.strip())\n",
    "        elif section_type == \"location\":\n",
    "            locations.append(current_section.strip())\n",
    "        elif section_type == \"character\":\n",
    "            characters.append(current_section.strip())\n",
    "\n",
    "    return summaries, locations, characters\n",
    "\n",
    "# Функция для сохранения данных в файлы\n",
    "def save_to_docx(data, output_path, title_prefix):\n",
    "    doc = Document()\n",
    "    for idx, section in enumerate(data, start=1):\n",
    "        doc.add_heading(f\"{title_prefix} {idx}\", level=1)\n",
    "        doc.add_paragraph(section)\n",
    "    doc.save(output_path)\n",
    "    print(f\"Сохранено: {output_path}\")\n",
    "\n",
    "# Функция для деления summaries на 3 части, не разрывая главы\n",
    "def split_summaries_evenly(summaries):\n",
    "    chunk_size = math.ceil(len(summaries) / 3)\n",
    "    chunks = []\n",
    "\n",
    "    start = 0\n",
    "    for i in range(3):\n",
    "        end = min(start + chunk_size, len(summaries))\n",
    "        chunks.append(summaries[start:end])\n",
    "        start = end\n",
    "\n",
    "    return chunks\n",
    "    \n",
    "def create_cover_info(docx_doc, path):\n",
    "    summary_label = \"События главы\"\n",
    "    location_label = \"Локации главы\"\n",
    "    character_label = \"Персонажи главы\"\n",
    "\n",
    "    output_path = path\n",
    "    summary = Document(f\"{output_path}/summary_clean.docx\")\n",
    "    summaries, locations, characters = extract_sections(summary, summary_label, location_label, character_label)\n",
    "    # Сохраняем основные файлы\n",
    "    save_to_docx(summaries, f\"{output_path}/synopsis.docx\", \"События главы\")\n",
    "    save_to_docx(locations, f\"{output_path}/locations.docx\", \"Локации главы\")\n",
    "    save_to_docx(characters, f\"{output_path}/characters.docx\", \"Персонажи главы\")\n",
    "\n",
    "    # Делим summaries на 3 части и сохраняем их\n",
    "    chunks = split_summaries_evenly(summaries)\n",
    "    for i, chunk in enumerate(chunks, start=1):\n",
    "        save_to_docx(chunk, f\"{output_path}/summary_part_{i}.docx\", \"Глава\")\n",
    "\n",
    "    print(\"Файлы успешно сохранены!\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b4402-07b2-42cc-b647-fc6a7e1ca711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
