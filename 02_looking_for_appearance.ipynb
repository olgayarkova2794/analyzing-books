{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31092458-80fc-4213-9f4d-125f26343469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–∞: million_dollar_bride/fulltext.docx\n",
      "üìñ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞...\n",
      "‚úÇÔ∏è –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –≥–ª–∞–≤—ã...\n",
      "‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è 'Clothes': –Ω–∞–π–¥–µ–Ω–æ 277 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π.\n",
      "‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è 'Hair': –Ω–∞–π–¥–µ–Ω–æ 178 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π.\n",
      "‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è 'Appearances': –Ω–∞–π–¥–µ–Ω–æ 129 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π.\n",
      "‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è 'Weather': –Ω–∞–π–¥–µ–Ω–æ 305 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π.\n",
      "‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è 'Locations': –Ω–∞–π–¥–µ–Ω–æ 201 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π.\n",
      "‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è 'Other': –Ω–∞–π–¥–µ–Ω–æ 2102 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π.\n",
      "üìä –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏...\n",
      "üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Excel...\n",
      "‚úÖ –§–∞–π–ª Excel —Å–æ–∑–¥–∞–Ω: million_dollar_bride/details.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "\n",
    "def extract_text_from_docx(file_path):\n",
    "    \"\"\"–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ DOCX-—Ñ–∞–π–ª–∞.\"\"\"\n",
    "    try:\n",
    "        doc = Document(file_path)\n",
    "        full_text = []\n",
    "        for paragraph in doc.paragraphs:\n",
    "            full_text.append(paragraph.text)\n",
    "        return '\\n'.join(full_text)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}\")\n",
    "        return None\n",
    "\n",
    "def search_words_in_chapter(chapter_text, words):\n",
    "    \"\"\"–ò—â–µ—Ç —Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–µ –≥–ª–∞–≤—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ö —Å –ø–æ–∑–∏—Ü–∏—è–º–∏.\"\"\"\n",
    "    word_pattern = r'\\b(' + '|'.join(re.escape(word) for word in words) + r')\\b'\n",
    "    matches = []\n",
    "\n",
    "    for match in re.finditer(word_pattern, chapter_text, re.IGNORECASE):\n",
    "        start, end = match.start(), match.end()\n",
    "\n",
    "        # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –≤–æ–∫—Ä—É–≥ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞\n",
    "        start_context = chapter_text[:start].split()[-8:]\n",
    "        end_context = chapter_text[end:].split()[:8]\n",
    "        found_word = chapter_text[start:end]\n",
    "        result = ' '.join(start_context + [found_word] + end_context)\n",
    "\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–∑–∏—Ü–∏—é –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "        matches.append((start, result))\n",
    "\n",
    "    return matches\n",
    "\n",
    "def search_in_all_chapters(chapters, words, category):\n",
    "    \"\"\"–ò—â–µ—Ç —Å–ª–æ–≤–∞ –≤–æ –≤—Å–µ—Ö –≥–ª–∞–≤–∞—Ö –∏ –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π.\"\"\"\n",
    "    total_matches = 0\n",
    "    results = []\n",
    "\n",
    "    for chapter_number, chapter_title, chapter_text in chapters:\n",
    "        matches = search_words_in_chapter(chapter_text, words)\n",
    "        total_matches += len(matches)\n",
    "\n",
    "        for position, match in matches:\n",
    "            results.append([chapter_number, chapter_title, position, match, category])\n",
    "\n",
    "    print(f\"‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏—è '{category}': –Ω–∞–π–¥–µ–Ω–æ {total_matches} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π.\")\n",
    "    return results\n",
    "\n",
    "def split_text_into_chapters(book_text):\n",
    "    \"\"\"–†–∞–∑–¥–µ–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –≥–ª–∞–≤—ã. –ü—Ä–∏–º–µ—Ä: —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–ª–æ–≤—É 'Chapter'.\"\"\"\n",
    "    chapters = []\n",
    "    chapter_texts = book_text.split('Chapter ')\n",
    "    for i, text in enumerate(chapter_texts[1:], start=1):\n",
    "        title_end = text.find('\\n')\n",
    "        chapter_title = text[:title_end].strip()\n",
    "        chapter_content = text[title_end + 1:].strip()\n",
    "        chapters.append((i, chapter_title, chapter_content))\n",
    "    return chapters\n",
    "\n",
    "def main(docx_file_path, chapters_folder):\n",
    "    \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –ø–æ–∏—Å–∫–∞.\"\"\"\n",
    "    print(f\"üìÇ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–∞: {docx_file_path}\")\n",
    "    if not os.path.exists(docx_file_path):\n",
    "        print(f\"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {docx_file_path}\")\n",
    "        return\n",
    "\n",
    "    print(\"üìñ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞...\")\n",
    "    book_text = extract_text_from_docx(docx_file_path)\n",
    "    if not book_text:\n",
    "        print(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞.\")\n",
    "        return\n",
    "\n",
    "    print(\"‚úÇÔ∏è –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –≥–ª–∞–≤—ã...\")\n",
    "    chapters = split_text_into_chapters(book_text)\n",
    "    if not chapters:\n",
    "        print(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –≥–ª–∞–≤—ã.\")\n",
    "        return\n",
    "\n",
    "    # –°–ø–∏—Å–∫–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞\n",
    "    clothes_words = ['stilettos', 'sunglasses', 'ring', 'necklace', 'bracelet', 'earrings', 'brooch', 'watch', 'anklet', 'choker', 'pendant', 'cufflinks', 'tie clip', 'nose ring', 'belly button ring', 'toe ring', 'hairpin', 'tiara', 'diadem', 'bangle', 'chain', 'medallion', 'pearl necklace', 'locket', 'armband', 'charm bracelet', 'dress', 'robe', 'suit', 'clothes', 'coat', 'jacket', 'shirt', 'pants', 'skirt', 'jeans', 't-shirt', 'sweater', 'blouse', 'shorts', 'hoodie', 'vest', 'scarf', 'hat', 'gloves', 'boots', 'shoes', 'sneakers', 'socks', 'tie', 'belt', 'gown', 'trench coat', 'blazer', 'cardigan', 'overalls', 'tank top', 'leggings']\n",
    "    hair_words = ['hair', 'beard', 'ponytail', 'bun', 'braids', 'bob', 'pixie cut', 'long waves', 'curly hair', 'straight hair', 'afro', 'buzz cut', 'french twist', 'dreadlocks', 'fishtail braid', 'half-up half-down', 'side part', 'middle part', 'updo', 'loose curls', 'locks', 'layered cut', 'shag cut', 'crew cut', 'mohawk', 'bangs', 'chignon', 'top knot']\n",
    "    appearances_words = ['fur', 'black wolf', 'white wolf', 'brown wolf', 'caramel hair', 'blonde', 'brunette', 'redhead', 'white hair', 'red hair', 'auburn hair', 'chestnut hair', 'black hair', 'grey hair', 'dark hair', 'blue eyes', 'blue irises', 'blue eyeballs', 'brown eyes', 'brown irises', 'brown eyeballs', 'black eyes', 'black irises', 'black eyeballs', 'red eyes', 'red irises', 'red eyeballs', 'hazel eyes', 'hazel irises', 'hazel eyeballs', 'green eyes', 'green irises', 'green eyeballs', 'eyes were green', 'eyes were black', 'eyes were brown', 'eyes were hazel', 'eyes were blue', 'eyes were grey', '5 feet', \"5'\", \"6'\", \"7'\", '6 feet', '7 feet', 'feet tall', 'slim', 'thin', 'thick', 'tall', 'dark skin', 'white skin', 'pale skin', 'freckles', 'tattoos', 'tattoo', 'brown skin', 'black skin', 'high cheekbones', 'wrinkles', 'wrinkled', 'full lips', 'small breasts', 'curves', 'big breasts']\n",
    "    other_words = ['eyes', 'face', 'skin', 'body', 'fur', 'chin', 'cheeks', 'big wolf', 'white wolf', 'beautiful', 'ugly', 'handsome', 'cute', 'gorgeous', 'sharp', 'features', 'arms', 'bicep', 'legs', 'ass', 'breasts', 'waist', 'muscular', 'pale', 'features', 'thin', 'fangs', 'tattoos', 'teeth', 'mouth', 'young', 'old', 'blood', 'bleeding', 'gaze', 'smirk', 'smile', 'lips', 'nose', 'hands', 'jaw']\n",
    "    weather_words = ['morning', 'afternoon', 'evening', 'night', 'sunrise', 'sunset', 'dawn', 'dusk', 'noon', 'midnight', 'cloudy', 'rain', 'storm', 'wind', 'sun', 'sunny', 'fog', 'foggy', 'snow', 'snowy', 'hail', 'thunder', 'lightning', 'breeze', 'chilly', 'hot', 'warm', 'cold', 'frost', 'blizzard', 'temperature', 'humid', 'dry', 'drizzle', 'pouring', 'downpour', 'mist', 'overcast']\n",
    "    locations_words = ['forest', 'living room', 'dining room', 'school', 'college', 'training grounds', 'field', 'bathroom', 'bedroom', 'cabin', 'house']\n",
    "    age_words = ['sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty', 'thirty', 'forty', 'fifty', 'twenties', 'thirties', 'years old', 'forties', 'fifties', 'sixties', 'seventies']\n",
    "   \n",
    "\n",
    "    all_results = []\n",
    "    for words, category in [\n",
    "        (clothes_words, 'Clothes'), (hair_words, 'Hair'),\n",
    "        (appearances_words, 'Appearances'), (weather_words, 'Weather'),\n",
    "        (locations_words, 'Locations'), (other_words, 'Other')\n",
    "    ]:\n",
    "        all_results.extend(search_in_all_chapters(chapters, words, category))\n",
    "\n",
    "    print(\"üìä –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏...\")\n",
    "    all_data_df = pd.DataFrame(all_results, columns=['Chapter Number', 'Chapter Title', 'Position', 'Match', 'Category'])\n",
    "    \n",
    "    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É –≥–ª–∞–≤—ã –∏ –ø–æ–∑–∏—Ü–∏–∏\n",
    "    all_data_df.sort_values(by=['Chapter Number', 'Position'], inplace=True)\n",
    "\n",
    "    print(\"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Excel...\")\n",
    "    os.makedirs(chapters_folder, exist_ok=True)\n",
    "    excel_file_path = f\"{chapters_folder}/details.xlsx\"\n",
    "    \n",
    "    # –£–±–∏—Ä–∞–µ–º –∫–æ–ª–æ–Ω–∫—É 'Position' –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º\n",
    "    try:\n",
    "        all_data_df.drop(columns=['Position']).to_excel(excel_file_path, sheet_name='Details', index=False)\n",
    "        print(f\"‚úÖ –§–∞–π–ª Excel —Å–æ–∑–¥–∞–Ω: {excel_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ Excel —Ñ–∞–π–ª–∞: {e}\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞\n",
    "chapters_folder = \"million_dollar_bride\"\n",
    "docx_file_path = f\"{chapters_folder}/fulltext.docx\"\n",
    "main(docx_file_path, chapters_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f09f63-835f-49e2-a137-824b7c60d6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
